import os
import pickle
import io
import re
import unicodedata
from typing import Iterable, Tuple, Optional, Union, Dict, List
from dotenv import load_dotenv

from telebot import TeleBot, types
from openai import OpenAI
import numpy as np
import pandas as pd
from pandas import ExcelWriter

from datetime import datetime
from openpyxl.utils import get_column_letter
from openpyxl.formatting.rule import FormulaRule
from openpyxl.styles import PatternFill

load_dotenv()

# ===================== CONFIG =====================
BOT_TOKEN = os.getenv("BOT_TOKEN")
MAIN_SHEET_NAME = "BUDG"  # read this sheet from the main file
ALLOWED_MAIN_COLUMNS = ["–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É", "–ì–ï–û", "–ó–∞–≥–∞–ª—å–Ω—ñ –≤–∏—Ç—Ä–∞—Ç–∏"]
ADDITIONAL_REQUIRED_COLS = ["–ö—Ä–∞—ó–Ω–∞", "–°—É–º–∞ –¥–µ–ø–æ–∑–∏—Ç—ñ–≤"]

# Flexible synonyms (users can rename columns ‚Äî we‚Äôll still find them)
GEO_COL_CANDIDATES = ["–ì–ï–û", "GEO", "Geo"]
OFFER_COL_CANDIDATES = ["–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É", "–û—Ñ—Ñ–µ—Ä", "Offer", "–ù–∞–∑–≤–∞ –æ—Ñ—Ñ–µ—Ä–∞", "–ù–∞–∑–≤–∞ –æ—Ñ—Ñ–µ—Ä—É"]

DEFAULT_PAIRS: list[tuple[str, str]] = [
    ("–ê—Ä–≥–µ–Ω—Ç–∏–Ω–∞", "TRAFCODE"),
    ("–ë–µ–Ω—ñ–Ω", "TRAFCODEx"),
]

OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-5")
OPENAI_MAX_CHARS = 60_000  # –±–µ–∑–ø–µ—á–Ω–∏–π –ª—ñ–º—ñ—Ç –¥–ª—è –æ–¥–Ω–æ–≥–æ –∑–∞–ø–∏—Ç—É
OPENAI_OUTPUT_COLUMN = "Total spend"  # –∫–æ–ª–æ–Ω–∫–∞, —è–∫—É –º–æ–¥–µ–ª—å –º–∞—î –∑–∞–ø–æ–≤–Ω–∏—Ç–∏/–ø–µ—Ä–µ—Ä–∞—Ö—É–≤–∞—Ç–∏

bot = TeleBot(BOT_TOKEN, parse_mode="HTML")

H_THRESH = 9.0  # H <= 9 is "good"
L_THRESH = 39.99  # L > 39.99 is "good" (strict >)
CPA_CAP = 11.0
EPS = 1e-12
EPS_YEL = 1e-6

# CPA Target defaults and overrides
CPA_DEFAULT_TARGET = 8
CPA_OVERRIDES: Dict[str, float] = {
    "–ê—Ä–≥–µ–Ω—Ç–∏–Ω–∞": 20,
    "–ë–æ–ª—ñ–≤—ñ—è": 15,
    "–í–µ–Ω–µ—Å—É–µ–ª–∞": 5,
    "–ì–∞–±–æ–Ω": 7,
    "–ì–∞–Ω–∞": 5,
    "–ï–∫–≤–∞–¥–æ—Ä": 15,
    "–ô–æ—Ä–¥–∞–Ω—ñ—è": 40,
    "–Ü—Ä–∞–∫": 40,
    "–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω": 30,
    "–ö–æ–ª—É–º–±—ñ—è": 11,
    "–ú–∞–ª–∞–π–∑—ñ—è": 40,
    "–ü–∞—Ä–∞–≥–≤–∞–π": 15,
    "–ü–∞–∫–∏—Å—Ç–∞–Ω": 15,
    "–ü–µ—Ä—É": 12,
    "–¢–∞—ó–ª–∞–Ω–¥": 22,
    "–£—Ä—É–≥–≤–∞–π": 12,
    "–§—ñ–ª—ñ–ø–ø—ñ–Ω–∏": 10,
}


# ===================== STATE =====================
class UserState:
    def __init__(self):
        self.alloc_mode = None
        self.phase = "WAIT_MAIN"  # WAIT_MAIN -> WAIT_ADDITIONAL, plus allocate flow
        self.main_agg_df: Optional[pd.DataFrame] = None
        self.offers: List[str] = []
        self.current_offer_index: int = 0
        self.offer_deposits: Dict[str, Dict[str, Dict[str, float]]] = {}

        # country maps
        self.country_map_uk_to_en = build_country_map_uk_to_en()
        self.country_map_ru_to_en = build_country_map_ru_to_en()
        self.country_canon = build_country_canonical()

        # --- allocate flow state ---
        self.alloc_df: Optional[pd.DataFrame] = None
        self.alloc_budget: Optional[float] = None
        self.alloc_pairs: Optional[list[tuple[str, str]]] = None
        # NEW: optional sets to control filtering and Total+% overrides
        self.current_pairs: Optional[set[tuple[str, str]]] = None
        self.plus35_pairs: Optional[set[tuple[str, str]]] = None


user_states: Dict[int, UserState] = {}

# ===== ACCESS CONTROL =====
# Retrieve and parse ALLOWED_USER_IDS
allowed_user_ids = os.getenv("ALLOWED_USER_IDS")
ALLOWED_USER_IDS = {uid.strip() for uid in allowed_user_ids.split(",") if uid.strip()}

print("Loaded user IDs:", ALLOWED_USER_IDS)

USERS_FILE = os.path.join("data", "telegram_users.txt")


def save_user_if_new(user: types.User, path: str = USERS_FILE) -> None:
    """
    –ó–±–µ—Ä—ñ–≥–∞—î —Ä—è–¥–æ–∫: <id>\t<first_name>\t<last_name>\t<username>
    –î–æ–¥–∞—î –ª–∏—à–µ, —è–∫—â–æ user.id —â–µ –≤—ñ–¥—Å—É—Ç–Ω—ñ–π —É —Ñ–∞–π–ª—ñ.
    """
    try:
        os.makedirs(os.path.dirname(path), exist_ok=True)
        user_id = str(user.id)
        first_name = user.first_name or ""
        last_name = user.last_name or ""
        username = user.username or ""

        # –í—ñ–¥–∫—Ä–∏–≤–∞—î–º–æ —É —Ä–µ–∂–∏–º—ñ a+ (—Å—Ç–≤–æ—Ä–∏—Ç—å —Ñ–∞–π–ª, —è–∫—â–æ –π–æ–≥–æ –Ω–µ–º–∞—î),
        # —á–∏—Ç–∞—î–º–æ –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —ñ, –∑–∞ –ø–æ—Ç—Ä–µ–±–∏, –¥–æ–ø–∏—Å—É—î–º–æ.
        with open(path, "a+", encoding="utf-8") as f:
            f.seek(0)
            exists = any(line.split("\t", 1)[0] == user_id for line in f)
            if not exists:
                f.write(f"{user_id}\t{first_name}\t{last_name}\t{username}\n")
    except Exception as e:
        # –ù–µ –ª–∞–º–∞—î–º–æ –ª–æ–≥—ñ–∫—É –±–æ—Ç–∞, –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–Ω–µ–º–æ (–∑–∞ –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ logger)
        try:
            print(f"Failed to save user to {path}: {e}")
        except:
            pass


def _deny_access_message():
    return (
        "‚õî <b>–î–æ—Å—Ç—É–ø –∑–∞–±–æ—Ä–æ–Ω–µ–Ω–æ.</b>\n"
        "–Ø–∫—â–æ –≤–∞–º –ø–æ—Ç—Ä—ñ–±–µ–Ω –¥–æ—Å—Ç—É–ø ‚Äî –∑–≤–µ—Ä–Ω—ñ—Ç—å—Å—è –¥–æ –∞–¥–º—ñ–Ω—ñ—Å—Ç—Ä–∞—Ç–æ—Ä–∞ –±–æ—Ç–∞."
    )


def _is_allowed_user(user_id: int) -> bool:
    return str(user_id) in ALLOWED_USER_IDS


# –î–ª—è message-—Ö–µ–Ω–¥–ª–µ—Ä—ñ–≤
def require_access(handler_func):
    def wrapper(message, *args, **kwargs):
        user_id = getattr(message.from_user, "id", None)
        if user_id is None or not _is_allowed_user(user_id):
            bot.reply_to(message, _deny_access_message())
            return
        return handler_func(message, *args, **kwargs)

    return wrapper


# –î–ª—è callback-query (—ñ–Ω–ª–∞–π–Ω-–∫–Ω–æ–ø–∫–∏)
def require_access_cb(handler_func):
    def wrapper(call, *args, **kwargs):
        user_id = getattr(call.from_user, "id", None)
        if user_id is None or not _is_allowed_user(user_id):
            try:
                bot.answer_callback_query(call.id, "‚õî –ù–µ–º–∞—î –¥–æ—Å—Ç—É–ø—É.")
            except Exception:
                pass
            bot.send_message(call.message.chat.id, _deny_access_message())
            return
        return handler_func(call, *args, **kwargs)

    return wrapper


def _df_to_csv(df: pd.DataFrame) -> str:
    # –ë–µ–∑ —ñ–Ω–¥–µ–∫—Å—É, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ ‚Äú–ø–ª–æ—Å–∫–æ‚Äù
    bio = io.StringIO()
    df.to_csv(bio, index=False)
    return bio.getvalue()


def _split_df_by_size(df: pd.DataFrame, max_chars: int = OPENAI_MAX_CHARS) -> list[pd.DataFrame]:
    """
    –î—ñ–ª–∏–º–æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –Ω–∞ —á–∞–Ω–∫–∏, —â–æ–± CSV –∫–æ–∂–Ω–æ–≥–æ –Ω–µ –ø–µ—Ä–µ–≤–∏—â—É–≤–∞–≤ –ª—ñ–º—ñ—Ç —Å–∏–º–≤–æ–ª—ñ–≤.
    """
    # –≥—Ä—É–±–∞ –æ—Ü—ñ–Ω–∫–∞ —Å–µ—Ä–µ–¥–Ω—å–æ–≥–æ —Ä–æ–∑–º—ñ—Ä—É —Ä—è–¥–∫–∞
    sample = min(len(df), 20)
    avg_row_len = len(_df_to_csv(df.head(sample))) / max(sample, 1)
    # –∑–∞–ø–∞—Å: —à–∞–ø–∫–∞ + –ø—Ä–æ–º–ø—Ç
    rows_per_chunk = max(5, int((max_chars - 3000) / max(avg_row_len, 1)))
    chunks = []
    for i in range(0, len(df), rows_per_chunk):
        chunks.append(df.iloc[i:i + rows_per_chunk].copy())
    return chunks


def _csv_from_text(text: str) -> str:
    """
    –í–∏—Ç—è–≥—É—î CSV –∑ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ (–ø—ñ–¥—Ç—Ä–∏–º–∫–∞ –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤ –±–µ–∑ –∫–æ–¥-–±–ª–æ–∫—ñ–≤ —Ç–∞ –∑ ```csv ... ```).
    """
    t = text.strip()
    if "```" in t:
        # –Ω–∞–º–∞–≥–∞—î–º–æ—Å—è –∑–Ω–∞–π—Ç–∏ fenced block
        parts = t.split("```")
        # —à—É–∫–∞—î–º–æ –±–ª–æ–∫ –∑ csv –∞–±–æ –ø–µ—Ä—à–∏–π –∫–æ–¥-–±–ª–æ–∫
        best = None
        for i in range(1, len(parts), 2):
            block = parts[i]
            if block.lstrip().lower().startswith("csv"):
                best = block.split("\n", 1)[1] if "\n" in block else ""
                break
        if best is None:
            # –±–µ—Ä–µ–º–æ –ø–µ—Ä—à–∏–π –∫–æ–¥-–±–ª–æ–∫ —è–∫ fallback
            best = parts[1]
        return best.strip()
    return t


SAVE_FILE = "saved_pairs.pkl"

# Global caches (used as single source of truth)
GLOBAL_CURRENT_PAIRS: set[tuple[str, str]] | None = None
GLOBAL_PLUS35_PAIRS: set[tuple[str, str]] | None = None


def save_pairs() -> None:
    """Persist global pairs once for the whole server."""
    data = {
        "current_pairs": GLOBAL_CURRENT_PAIRS,
        "plus35_pairs": GLOBAL_PLUS35_PAIRS,
    }
    with open(SAVE_FILE, "wb") as f:
        pickle.dump(data, f)


def load_pairs() -> None:
    """Load global pairs into GLOBAL_* variables (no per-user binding)."""
    global GLOBAL_CURRENT_PAIRS, GLOBAL_PLUS35_PAIRS
    if not os.path.exists(SAVE_FILE):
        GLOBAL_CURRENT_PAIRS, GLOBAL_PLUS35_PAIRS = None, None
        return
    with open(SAVE_FILE, "rb") as f:
        data = pickle.load(f) or {}
    GLOBAL_CURRENT_PAIRS = data.get("current_pairs")
    GLOBAL_PLUS35_PAIRS = data.get("plus35_pairs")


load_pairs()


# ===================== NORMALIZATION (countries) =====================
def normalize_text(s: str) -> str:
    return re.sub(r"\s+", " ", str(s)).strip().lower()


def build_country_map_uk_to_en() -> Dict[str, str]:
    m = {
        "–ê—Ä–≥–µ–Ω—Ç–∏–Ω–∞": "Argentina",
        "–ë–µ–Ω—ñ–Ω": "Benin",
        "–ë—É—Ä–∫—ñ–Ω–∞-–§–∞—Å–æ": "Burkina Faso",
        "–í–µ–Ω–µ—Å—É–µ–ª–∞": "Venezuela",
        "–ì–∞–±–æ–Ω": "Gabon",
        "–ì–∞—ó—Ç—ñ": "Haiti",
        "–ì–∞–Ω–∞": "Ghana",

        # ‚ùó —É—Ç–æ—á–Ω–µ–Ω–Ω—è: —É XLSX –∑—É—Å—Ç—Ä—ñ—á–∞—î—Ç—å—Å—è "Guinea-Conakry"
        # —â–æ–± –∑–≤‚Äô—è–∑–∞—Ç–∏ –∑ –¥–æ–¥. —Ç–∞–±–ª–∏—Ü—è–º–∏, –º–∞–ø–∏–º–æ —É–∫—Ä "–ì–≤—ñ–Ω–µ—è" —Å–∞–º–µ –Ω–∞ "Guinea-Conakry"
        # (–¥–∞–ª—ñ –≤ –∫–∞–Ω–æ–Ω—ñ –∑–≤–µ–¥–µ–º–æ —Ü–µ –¥–æ "Guinea")
        "–ì–≤—ñ–Ω–µ—è": "Guinea-Conakry",

        # ---- DRC/ROC ----
        "–î–µ–º–æ–∫—Ä–∞—Ç–∏—á–Ω–∞ –†–µ—Å–ø—É–±–ª—ñ–∫–∞ –ö–æ–Ω“ë–æ": "Congo (Kinshasa)",
        "–î–† –ö–æ–Ω–≥–æ": "Congo (Kinshasa)",
        "–ö–æ–Ω–≥–æ (–ö—ñ–Ω—à–∞—Å–∞)": "Congo (Kinshasa)",
        "–†–µ—Å–ø—É–±–ª—ñ–∫–∞ –ö–æ–Ω–≥–æ": "Congo (Brazzaville)",
        "–ö–æ–Ω–≥–æ-–ë—Ä–∞–∑–∑–∞–≤—ñ–ª—å": "Congo (Brazzaville)",
        # —è–∫—â–æ –ø—Ä–æ—Å—Ç–æ "–ö–æ–Ω–≥–æ" ‚Äî –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º DRC
        "–ö–æ–Ω–≥–æ": "Congo (Brazzaville)",

        "–ö–∞–º–µ—Ä—É–Ω": "Cameroon",

        # –ö–æ—Ç-–¥‚Äô–Ü–≤—É–∞—Ä ‚Äî –æ–¥—Ä–∞–∑—É –∫—ñ–ª—å–∫–∞ –∞–ø–æ—Å—Ç—Ä–æ—Ñ–Ω–∏—Ö –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤
        "–ö–æ—Ç-–¥'–Ü–≤—É–∞—Ä": "Cote d'Ivoire",
        "–ö–æ—Ç-–¥‚Äô–Ü–≤—É–∞—Ä": "Cote d'Ivoire",
        "–ö–æ—Ç –¥‚Äô–Ü–≤—É–∞—Ä": "Cote d'Ivoire",

        "–ö–µ–Ω—ñ—è": "Kenya",
        "–°–µ–Ω–µ–≥–∞–ª": "Senegal",
        "–°—å—î—Ä—Ä–∞-–õ–µ–æ–Ω–µ": "Sierra Leone",
        "–¢–∞–Ω–∑–∞–Ω—ñ—è": "Tanzania",
        "–¢–æ–≥–æ": "Togo",
        "–£–≥–∞–Ω–¥–∞": "Uganda",
        "–ó–∞–º–±—ñ—è": "Zambia",
        "–ï—Ñ—ñ–æ–ø—ñ—è": "Ethiopia",
        "–ù—ñ–≥–µ—Ä": "Niger",
        "–ù—ñ–≥–µ—Ä—ñ—è": "Nigeria",
        "–ú–∞–ª—ñ": "Mali",
        "–ü–∞–∫–∏—Å—Ç–∞–Ω": "Pakistan",
        "–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω": "Kazakhstan",
        "–Ü—Å–ø–∞–Ω—ñ—è": "Spain",
        "–§—Ä–∞–Ω—Ü—ñ—è": "France",
        "–Ü—Ç–∞–ª—ñ—è": "Italy",
        "–ü–æ—Ä—Ç—É–≥–∞–ª—ñ—è": "Portugal",
        "–î–æ–º—ñ–Ω—ñ–∫–∞–Ω—Å—å–∫–∞ –†–µ—Å–ø—É–±–ª—ñ–∫–∞": "Dominican Republic",
        "–ö–∞–Ω–∞–¥–∞": "Canada",
        "–§—ñ–ª—ñ–ø–ø—ñ–Ω–∏": "Philippines",

        # üîπ –¥–æ–¥–∞–Ω–æ –∑ –≤–∞—à–æ–≥–æ —Å–ø–∏—Å–∫—É ¬´missing¬ª
        "–ë–æ–ª—ñ–≤—ñ—è": "Bolivia",
        "–ï–∫–≤–∞–¥–æ—Ä": "Ecuador",
        "–ö–æ–ª—É–º–±—ñ—è": "Colombia",
        "–ü–∞—Ä–∞–≥–≤–∞–π": "Paraguay",
        "–ü–µ—Ä—É": "Peru",
    }
    return {normalize_text(k): v for k, v in m.items()}


def build_country_map_ru_to_en() -> Dict[str, str]:
    m = {
        "–ê—Ä–≥–µ–Ω—Ç–∏–Ω–∞": "Argentina",
        "–ë–µ–Ω–∏–Ω": "Benin",
        "–ë—É—Ä–∫–∏–Ω–∞-–§–∞—Å–æ": "Burkina Faso",
        "–í–µ–Ω–µ—Å—É—ç–ª–∞": "Venezuela",
        "–ì–∞–±–æ–Ω": "Gabon",
        "–ì–∞–∏—Ç–∏": "Haiti",
        "–ì–∞–Ω–∞": "Ghana",

        # –ö–∞–∫ –∏ –≤ UA-–∫–∞—Ä—Ç–µ: "–ì–≤–∏–Ω–µ—è" ‚Üí "Guinea-Conakry" (–¥–∞–ª–µ–µ –∫–∞–Ω–æ–Ω–∏–∑–∏—Ä—É–µ–º –≤ "Guinea")
        "–ì–≤–∏–Ω–µ—è": "Guinea-Conakry",

        # ---- DRC/ROC ----
        "–î–µ–º–æ–∫—Ä–∞—Ç–∏—á–µ—Å–∫–∞—è –†–µ—Å–ø—É–±–ª–∏–∫–∞ –ö–æ–Ω–≥–æ": "Congo (Kinshasa)",
        "–î–† –ö–æ–Ω–≥–æ": "Congo (Kinshasa)",
        "–ö–æ–Ω–≥–æ (–ö–∏–Ω—à–∞—Å–∞)": "Congo (Kinshasa)",
        "–†–µ—Å–ø—É–±–ª–∏–∫–∞ –ö–æ–Ω–≥–æ": "Congo (Brazzaville)",
        "–ö–æ–Ω–≥–æ-–ë—Ä–∞–∑–∑–∞–≤–∏–ª—å": "Congo (Brazzaville)",
        # –µ—Å–ª–∏ –ø—Ä–æ—Å—Ç–æ "–ö–æ–Ω–≥–æ" ‚Äî –∫–∞–∫ –≤ UA-–∫–∞—Ä—Ç–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º Brazzaville
        "–ö–æ–Ω–≥–æ": "Congo (Brazzaville)",

        "–ö–∞–º–µ—Ä—É–Ω": "Cameroon",

        # –ö–æ—Ç-–¥‚Äô–ò–≤—É–∞—Ä ‚Äî —Ä–∞–∑–Ω—ã–µ –∞–ø–æ—Å—Ç—Ä–æ—Ñ—ã/–ø—Ä–æ–±–µ–ª—ã
        "–ö–æ—Ç-–¥'–ò–≤—É–∞—Ä": "Cote d'Ivoire",
        "–ö–æ—Ç-–¥‚Äô–ò–≤—É–∞—Ä": "Cote d'Ivoire",
        "–ö–æ—Ç –¥‚Äô–ò–≤—É–∞—Ä": "Cote d'Ivoire",

        "–ö–µ–Ω–∏—è": "Kenya",
        "–°–µ–Ω–µ–≥–∞–ª": "Senegal",
        "–°—å–µ—Ä—Ä–∞-–õ–µ–æ–Ω–µ": "Sierra Leone",
        "–¢–∞–Ω–∑–∞–Ω–∏—è": "Tanzania",
        "–¢–æ–≥–æ": "Togo",
        "–£–≥–∞–Ω–¥–∞": "Uganda",
        "–ó–∞–º–±–∏—è": "Zambia",
        "–≠—Ñ–∏–æ–ø–∏—è": "Ethiopia",
        "–ù–∏–≥–µ—Ä": "Niger",
        "–ù–∏–≥–µ—Ä–∏—è": "Nigeria",
        "–ú–∞–ª–∏": "Mali",
        "–ü–∞–∫–∏—Å—Ç–∞–Ω": "Pakistan",
        "–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω": "Kazakhstan",
        "–ò—Å–ø–∞–Ω–∏—è": "Spain",
        "–§—Ä–∞–Ω—Ü–∏—è": "France",
        "–ò—Ç–∞–ª–∏—è": "Italy",
        "–ü–æ—Ä—Ç—É–≥–∞–ª–∏—è": "Portugal",
        "–î–æ–º–∏–Ω–∏–∫–∞–Ω—Å–∫–∞—è –†–µ—Å–ø—É–±–ª–∏–∫–∞": "Dominican Republic",
        "–ö–∞–Ω–∞–¥–∞": "Canada",
        "–§–∏–ª–∏–ø–ø–∏–Ω—ã": "Philippines",

        # –õ–∞—Ç–∞–º (–∫–∞–∫ –≤ UA-–∫–∞—Ä—Ç–µ)
        "–ë–æ–ª–∏–≤–∏—è": "Bolivia",
        "–≠–∫–≤–∞–¥–æ—Ä": "Ecuador",
        "–ö–æ–ª—É–º–±–∏—è": "Colombia",
        "–ü–∞—Ä–∞–≥–≤–∞–π": "Paraguay",
        "–ü–µ—Ä—É": "Peru",
    }
    return {normalize_text(k): v for k, v in m.items()}


def build_country_canonical() -> Dict[str, str]:
    canon = {
        # —Å–∞–º–æ–∫–∞–Ω–æ–Ω—ñ—á–Ω—ñ EN
        "Argentina": "Argentina",
        "Benin": "Benin",
        "Burkina Faso": "Burkina Faso",
        "Gabon": "Gabon",
        "Haiti": "Haiti",
        "Ghana": "Ghana",
        "Guinea": "Guinea",
        "Congo (Kinshasa)": "Congo (Kinshasa)",
        "Congo (Brazzaville)": "Congo (Brazzaville)",
        "Cameroon": "Cameroon",
        "Cote d'Ivoire": "Cote d'Ivoire",
        "Kenya": "Kenya",
        "Senegal": "Senegal",
        "Sierra Leone": "Sierra Leone",
        "Tanzania": "Tanzania",
        "Togo": "Togo",
        "Uganda": "Uganda",
        "Venezuela": "Venezuela",
        "Zambia": "Zambia",
        "Ethiopia": "Ethiopia",
        "Niger": "Niger",
        "Nigeria": "Nigeria",
        "Mali": "Mali",
        "Pakistan": "Pakistan",
        "Kazakhstan": "Kazakhstan",
        "Spain": "Spain",
        "France": "France",
        "Italy": "Italy",
        "Portugal": "Portugal",
        "Dominican Republic": "Dominican Republic",
        "Canada": "Canada",
        "Philippines": "Philippines",

        # üîπ –¥–æ–¥–∞–Ω–æ –∑ –≤–∞—à–æ–≥–æ —Å–ø–∏—Å–∫—É ¬´missing¬ª
        "Bolivia": "Bolivia",
        "Ecuador": "Ecuador",
        "Colombia": "Colombia",
        "Paraguay": "Paraguay",
        "Peru": "Peru",

        # —Å–∏–Ω–æ–Ω—ñ–º–∏/–≤–∞—Ä—ñ–∞–Ω—Ç–∏ –Ω–∞–ø–∏—Å–∞–Ω–Ω—è ‚Üí –∫–∞–Ω–æ–Ω
        # Cote d'Ivoire
        "Cote DIvoire": "Cote d'Ivoire",
        "Cote dIvoire": "Cote d'Ivoire",
        "Cote D Ivoire": "Cote d'Ivoire",
        "Cote d‚Äôivoire": "Cote d'Ivoire",
        "C√¥te d‚ÄôIvoire": "Cote d'Ivoire",
        "Ivory Coast": "Cote d'Ivoire",

        # Guinea-Conakry ‚Üí Guinea
        "Guinea-Conakry": "Guinea",
        "Guinea Conakry": "Guinea",
        "Guinea, Conakry": "Guinea",

        # DRC/ROC –≤–∞—Ä—ñ–∞–Ω—Ç–∏
        "DRC": "Congo (Kinshasa)",
        "DR Congo": "Congo (Kinshasa)",
        "Congo (DRC)": "Congo (Kinshasa)",
        "Democratic Republic of the Congo": "Congo (Kinshasa)",
        "Democratic Republic of Congo": "Congo (Kinshasa)",
        "Congo-Kinshasa": "Congo (Kinshasa)",

        "Republic of the Congo": "Congo (Brazzaville)",
        "Congo Republic": "Congo (Brazzaville)",
        "Congo-Brazzaville": "Congo (Brazzaville)",

        # UA ‚Üí EN –∫–∞–Ω–æ–Ω (–Ω–∞ –≤–∏–ø–∞–¥–æ–∫, —è–∫—â–æ –¥–µ—Å—å –ø—Ä–æ—Å–æ—á–∏—Ç—å—Å—è —É–∫—Ä —É –¥–æ–¥. —Ç–∞–±–ª–∏—Ü—è—Ö)
        "–∫–æ—Ç-–¥'—ñ–≤—É–∞—Ä": "Cote d'Ivoire",
        "–∫–æ—Ç-–¥‚Äô—ñ–≤—É–∞—Ä": "Cote d'Ivoire",
        "–∫–æ—Ç –¥‚Äô—ñ–≤—É–∞—Ä": "Cote d'Ivoire",
        "–≥–≤—ñ–Ω–µ—è": "Guinea",
        "–±–æ–ª—ñ–≤—ñ—è": "Bolivia",
        "–µ–∫–≤–∞–¥–æ—Ä": "Ecuador",
        "–∫–æ–ª—É–º–±—ñ—è": "Colombia",
        "–ø–∞—Ä–∞–≥–≤–∞–π": "Paraguay",
        "–ø–µ—Ä—É": "Peru",
    }
    return {normalize_text(k): v for k, v in canon.items()}


def to_canonical_en(
        country: str,
        uk_to_en: Dict[str, str],
        canonical: Dict[str, str],
        ru_to_en: Optional[Dict[str, str]] = None,
) -> str:
    key = normalize_text(country)

    # 1) UA ‚Üí EN
    if key in uk_to_en:
        mapped = uk_to_en[key]
        return canonical.get(normalize_text(mapped), mapped)

    # 2) RU ‚Üí EN (—Ä–µ–∑–µ—Ä–≤, —è–∫—â–æ –Ω–µ –∑–Ω–∞–π—à–ª–∏ –≤ UA)
    if ru_to_en and key in ru_to_en:
        mapped = ru_to_en[key]
        return canonical.get(normalize_text(mapped), mapped)

    # 3) –£–∂–µ EN/–≤–∞—Ä—ñ–∞–Ω—Ç ‚Äî –∫–∞–Ω–æ–Ω—ñ–∑—É—î–º–æ
    if key in canonical:
        return canonical[key]

    # 4) –°–ø–µ—Ü–≤–∏–ø–∞–¥–∫–∏
    if key in {"–∫–æ–Ω–≥–æ", "congo"}:
        return "Congo (Kinshasa)"

    # 5) –Ø–∫ —î (–Ω–µ –≤–ø—ñ–∑–Ω–∞–ª–∏)
    return country


def cpa_target_for_geo(geo: Optional[str]) -> float:
    try:
        key = str(geo).strip()
    except Exception:
        key = ""
    return CPA_OVERRIDES.get(key, CPA_DEFAULT_TARGET)


# ===================== FLEXIBLE HEADER / COLUMN MATCH =====================

def detect_header_row(df: pd.DataFrame, required: List[str], max_scan: int = 60,
                      scan_rows: Optional[int] = None) -> int:
    # accept either max_scan or scan_rows for backward compatibility
    if scan_rows is not None:
        max_scan = scan_rows
    req_norm = [normalize_text(r) for r in required]
    for i in range(min(max_scan, len(df))):
        row_vals = [normalize_text(x) for x in list(df.iloc[i].values)]
        if all(any(h == v for v in row_vals) for h in req_norm):
            return i
    return 0


def match_columns(actual_cols, required_labels: List[str]) -> Optional[Dict[str, str]]:
    norm_actual = {normalize_text(str(c)): str(c) for c in actual_cols}
    out = {}
    for need in required_labels:
        key = normalize_text(need)
        if key in norm_actual:
            out[need] = norm_actual[key]
            continue
        # punctuation-insensitive
        found = None
        for k, v in norm_actual.items():
            if normalize_text(re.sub(r"[^\w\s'‚Äô]", "", k)) == normalize_text(re.sub(r"[^\w\s'‚Äô]", "", key)):
                found = v
                break
        if not found:
            return None
        out[need] = found
    return out


# ===================== FILE READERS =====================
# ADD
def read_excel_robust(file_bytes: bytes, sheet_name: str, header: int = 0) -> pd.DataFrame:
    """
    Robust Excel reader with multiple fallback strategies.
    Filters to the current month:
      - Prefer column '–ú—ñ—Å—è—Ü—å' (numeric month: 1..12).
      - Fallback to column '–î–∞—Ç–∞' (dd/mm/YYYY).
    """
    bio = io.BytesIO(file_bytes)
    errors = []

    # Helper: filter to current month
    def filter_current_month(df: pd.DataFrame) -> pd.DataFrame:
        cur_month = datetime.now().month

        if "–ú—ñ—Å—è—Ü—å" in df.columns:
            # Accept strings like "09", numbers like 9.0, etc.
            month_series = pd.to_numeric(df["–ú—ñ—Å—è—Ü—å"], errors="coerce")
            return df[month_series == cur_month]

        return df

    # Strategy 1: openpyxl
    try:
        bio.seek(0)
        df = pd.read_excel(bio, sheet_name=sheet_name, header=header, engine="openpyxl")
        return filter_current_month(df)
    except Exception as e:
        errors.append(f"openpyxl: {e}")
        print(f"openpyxl failed: {e}")

    # Strategy 2: openpyxl without header, set manually
    try:
        bio.seek(0)
        df_raw = pd.read_excel(bio, sheet_name=sheet_name, header=None, engine="openpyxl")
        if header > 0:
            new_header = df_raw.iloc[header].tolist()
            df = df_raw.iloc[header + 1:].reset_index(drop=True)
            df.columns = new_header
        else:
            df = df_raw
        return filter_current_month(df)
    except Exception as e:
        errors.append(f"openpyxl manual header: {e}")
        print(f"Manual header setting failed: {e}")

    # Strategy 3: calamine
    try:
        bio.seek(0)
        df = pd.read_excel(bio, sheet_name=sheet_name, header=header, engine="calamine")
        return filter_current_month(df)
    except Exception as e:
        errors.append(f"calamine: {e}")
        print(f"calamine failed: {e}")

    # Strategy 4: xlrd
    try:
        bio.seek(0)
        df = pd.read_excel(bio, sheet_name=sheet_name, header=header, engine="xlrd")
        return filter_current_month(df)
    except Exception as e:
        errors.append(f"xlrd: {e}")
        print(f"xlrd failed: {e}")

    raise ValueError(f"Could not read Excel file with any engine. Errors: {'; '.join(errors)}")


def load_pairs_table(
        pairs_source: Union[str, pd.DataFrame],
        *,
        geo_col: Optional[str] = None,
        offer_col: Optional[str] = None,
) -> list[tuple[str, str]]:
    """
    Load a user-submitted table of unique (–ì–ï–û, –û—Ñ—Ñ–µ—Ä) pairs.
    - pairs_source: path to .csv/.xlsx OR a pandas DataFrame
    - geo_col/offer_col: optional explicit column names (override auto-detect)
    Returns: list of (geo, offer) tuples, de-duplicated, stripped, non-empty.
    Raises: ValueError with a friendly message on problems.
    """
    # 1) Load
    if isinstance(pairs_source, pd.DataFrame):
        df = pairs_source.copy()
    elif isinstance(pairs_source, str):
        if pairs_source.lower().endswith(".csv"):
            df = pd.read_csv(pairs_source)
        elif pairs_source.lower().endswith((".xlsx", ".xls")):
            df = pd.read_excel(pairs_source)
        else:
            raise ValueError("Unsupported file type. Use .csv or .xlsx, or pass a DataFrame.")
    else:
        raise ValueError("pairs_source must be a DataFrame or a path to .csv/.xlsx")

    # 2) Find columns
    def pick_col(cands: Iterable[str]) -> Optional[str]:
        for c in cands:
            if c in df.columns:
                return c
        return None

    g_col = geo_col or pick_col(GEO_COL_CANDIDATES)
    o_col = offer_col or pick_col(OFFER_COL_CANDIDATES)

    if not g_col or not o_col:
        raise ValueError(
            "Table must contain columns for GEO and Offer. "
            f"Tried GEO in {GEO_COL_CANDIDATES}, Offer in {OFFER_COL_CANDIDATES}. "
            "You can also pass geo_col=... and offer_col=...."
        )

    # 3) Clean & validate rows
    sub = (
        df[[g_col, o_col]]
        .astype(str)
        .apply(lambda s: s.str.strip())
        .dropna()
        .replace({"": pd.NA})
        .dropna()
        .drop_duplicates()
    )

    if sub.empty:
        raise ValueError("Pairs table is empty after cleaning (no valid (–ì–ï–û, –û—Ñ—Ñ–µ—Ä) rows).")

    # 4) To list of tuples
    pairs: list[tuple[str, str]] = list(sub.itertuples(index=False, name=None))
    return pairs


def load_main_budg_table(file_bytes: bytes, filename: str = "uploaded") -> pd.DataFrame:
    df = None
    errors = []

    if filename.lower().endswith((".xlsx", ".xls", ".xlsm")):
        try:
            df = read_excel_robust(file_bytes, sheet_name="BUDG", header=1)
        except Exception as e1:
            errors.append(f"header=1: {e1}")
            # (your existing Excel fallback logic remains unchanged)
    else:
        # CSV support
        bio = io.BytesIO(file_bytes)
        try:
            df_raw = pd.read_csv(bio, header=None)
        except Exception:
            bio.seek(0)
            try:
                df_raw = pd.read_csv(bio, header=None, encoding="cp1251")
            except Exception:
                bio.seek(0)
                df_raw = pd.read_csv(bio, header=None, encoding="utf-8")

        # detect header row (similar to Excel logic)
        header_row = -1
        for i in range(min(10, len(df_raw))):
            row_values = [str(v).lower().strip() for v in df_raw.iloc[i].values]
            if any("–Ω–∞–∑–≤–∞" in val and "–æ—Ñ—Ñ–µ—Ä" in val for val in row_values) and \
                    any("–≥–µ–æ" in val for val in row_values) and \
                    any("–≤–∏—Ç—Ä–∞—Ç" in val for val in row_values):
                header_row = i
                break

        if header_row >= 0:
            new_header = df_raw.iloc[header_row].tolist()
            df = df_raw.iloc[header_row + 1:].reset_index(drop=True)
            df.columns = new_header
        else:
            df = df_raw

        # --- filter current month ---
        # cur_month = datetime.now().month
        cur_month = 10

        if "–ú—ñ—Å—è—Ü—å" in df.columns:
            df["–ú—ñ—Å—è—Ü—å"] = pd.to_numeric(df["–ú—ñ—Å—è—Ü—å"], errors="coerce")
            df = df[df["–ú—ñ—Å—è—Ü—å"] == cur_month]
        elif "–î–∞—Ç–∞" in df.columns:
            df["–î–∞—Ç–∞"] = pd.to_datetime(df["–î–∞—Ç–∞"], format="%d/%m/%Y", errors="coerce")
            df = df[(df["–î–∞—Ç–∞"].dt.month == cur_month) & (df["–î–∞—Ç–∞"].dt.year == datetime.now().year)]

    if df is None:
        raise ValueError(f"Could not load BUDG sheet. Errors: {'; '.join(errors)}")

    # clean column names
    df.columns = [str(c).replace("\xa0", " ").replace("\u00A0", " ").strip() for c in df.columns]

    # validate and map columns
    colmap = match_columns(df.columns, ALLOWED_MAIN_COLUMNS)
    if not colmap:
        available = [str(c) for c in df.columns]
        required = ALLOWED_MAIN_COLUMNS
        raise ValueError(
            f"–£ BUDG –º–∞—é—Ç—å –±—É—Ç–∏ –∫–æ–ª–æ–Ω–∫–∏: {required}.\n"
            f"–î–æ—Å—Ç—É–ø–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: {available}\n"
            f"–ü–µ—Ä–µ–≤—ñ—Ä –Ω–∞–∑–≤–∏ –∫–æ–ª–æ–Ω–æ–∫ —É —Ñ–∞–π–ª—ñ."
        )

    df = df[[colmap["–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É"], colmap["–ì–ï–û"], colmap["–ó–∞–≥–∞–ª—å–Ω—ñ –≤–∏—Ç—Ä–∞—Ç–∏"]]].copy()
    df.columns = ["–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É", "–ì–ï–û", "–ó–∞–≥–∞–ª—å–Ω—ñ –≤–∏—Ç—Ä–∞—Ç–∏"]

    return df


def read_additional_table(file_bytes: bytes, filename: str) -> pd.DataFrame:
    """
    Read additional table with improved error handling
    """
    bio = io.BytesIO(file_bytes)

    if filename.lower().endswith((".xlsx", ".xls", ".xlsm")):
        # Try multiple strategies for Excel files
        try:
            df_raw = pd.read_excel(bio, header=None, engine="openpyxl")
        except Exception:
            try:
                bio.seek(0)
                df_raw = pd.read_excel(bio, header=None, engine="calamine")
            except Exception:
                bio.seek(0)
                df_raw = pd.read_excel(bio, header=None, engine="xlrd")
    else:
        # CSV files
        try:
            df_raw = pd.read_csv(bio, header=None)
        except Exception:
            bio.seek(0)
            try:
                df_raw = pd.read_csv(bio, header=None, encoding="cp1251")
            except Exception:
                bio.seek(0)
                df_raw = pd.read_csv(bio, header=None, encoding="utf-8")

    # Find header row
    header_idx = detect_header_row(df_raw, [normalize_text(x) for x in ADDITIONAL_REQUIRED_COLS])

    # Validate header row exists
    if header_idx >= len(df_raw):
        raise ValueError(f"–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤ —É —Ñ–∞–π–ª—ñ {filename}")

    headers = df_raw.iloc[header_idx].tolist()
    data = df_raw.iloc[header_idx + 1:].reset_index(drop=True)
    data.columns = headers

    # Clean column names
    data.columns = [str(c).replace("\xa0", " ").replace("\u00A0", " ").strip() for c in data.columns]

    col_map = match_columns(data.columns, ADDITIONAL_REQUIRED_COLS)
    if not col_map:
        available = [str(c) for c in data.columns]
        required = ADDITIONAL_REQUIRED_COLS
        raise ValueError(
            f"–£ —Ñ–∞–π–ª—ñ {filename} –º–∞—é—Ç—å –±—É—Ç–∏ –∫–æ–ª–æ–Ω–∫–∏: {required}.\n"
            f"–î–æ—Å—Ç—É–ø–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: {available}\n"
            f"–ü–µ—Ä–µ–≤—ñ—Ä –Ω–∞–∑–≤–∏ –∫–æ–ª–æ–Ω–æ–∫ —É —Ñ–∞–π–ª—ñ."
        )

    df = data[[col_map["–ö—Ä–∞—ó–Ω–∞"], col_map["–°—É–º–∞ –¥–µ–ø–æ–∑–∏—Ç—ñ–≤"]]].copy()
    df.columns = ["–ö—Ä–∞—ó–Ω–∞", "–°—É–º–∞ –¥–µ–ø–æ–∑–∏—Ç—ñ–≤"]
    return df


# ===================== HELPERS =====================

def inject_formulas_and_cf(
        ws,
        *,
        header_row: int = 1,
        first_data_row: int = 2,
        last_data_row: int | None = None,
):
    """
    –î–æ–¥–∞—î —Ñ–æ—Ä–º—É–ª–∏ —É –∫–æ–ª–æ–Ω–∫–∏ —Ç–∞ CF-–ø—ñ–¥—Å–≤—ñ—Ç–∫—É.
    –û—á—ñ–∫—É—î—Ç—å—Å—è, —â–æ —É —à–∞–ø—Ü—ñ –≤–∂–µ —î –ø—Ä–∏–Ω–∞–π–º–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏:
    - 'Total spend' (F), 'FTD qty' (E), 'Total Dep Amount' (K), 'My deposit amount' (L)
    –Ø–∫—â–æ —ñ–Ω—à–∏—Ö –∫–æ–ª–æ–Ω–æ–∫ (Total+%, CPA, –°P/–ß, Target 40/50%) –Ω–µ–º–∞—î ‚Äî —Å—Ç–≤–æ—Ä–∏–º–æ.

    –§–æ—Ä–º—É–ª–∏:
      G: Total+%                 = Total spend * 1.3
      H: CPA                     = Total+% / FTD qty
      (–∫–∏—Ä–∏–ª–∏—Ü—è) '–°P/–ß'          = Total Dep Amount / FTD qty
      'C. profit Target 40%'     = Total+% * 0.4
      'C. profit Target 50%'     = Total+% * 0.5
      L: My deposit amount       = Total Dep Amount / Total+% * 100

    """

    if last_data_row is None:
        last_data_row = ws.max_row
    if last_data_row < first_data_row:
        return

    # --- Map header name -> column index (—Å—Ç–≤–æ—Ä—é—î–º–æ, —è–∫—â–æ —Ç—Ä–µ–±–∞)
    headers = {ws.cell(row=header_row, column=c).value: c for c in range(1, ws.max_column + 1) if
               ws.cell(row=header_row, column=c).value}

    def ensure_col(name: str) -> int:
        if name in headers:
            return headers[name]
        col = ws.max_column + 1
        ws.cell(row=header_row, column=col, value=name)
        headers[name] = col
        return col

    col_idx = {
        "Total spend": ensure_col("Total spend"),
        "FTD qty": ensure_col("FTD qty"),
        "Total Dep Amount": ensure_col("Total Dep Amount"),
        "My deposit amount": ensure_col("My deposit amount"),
        "Total+%": ensure_col("Total+%"),
        "CPA": ensure_col("CPA"),
        "CPA Target": ensure_col("CPA Target"),
        "–°P/–ß": ensure_col("–°P/–ß"),  # –ø–µ—Ä—à–∞ –ª—ñ—Ç–µ—Ä–∞ ‚Äî –∫–∏—Ä–∏–ª–∏—á–Ω–∞ "–°"
        "C. profit Target 40%": ensure_col("C. profit Target 40%"),
        "C. profit Target 50%": ensure_col("C. profit Target 50%"),
    }

    # –£ –∑—Ä—É—á–Ω—ñ –∑–º—ñ–Ω–Ω—ñ ‚Äî –∫–æ–ª. –ª—ñ—Ç–µ—Ä–∏
    letter = {k: get_column_letter(v) for k, v in col_idx.items()}

    F = letter["Total spend"]
    E = letter["FTD qty"]
    K = letter["Total Dep Amount"]
    L = letter["My deposit amount"]
    G = letter["Total+%"]
    H = letter["CPA"]
    I = letter["CPA Target"]
    CPCH = letter["–°P/–ß"]
    C40 = letter["C. profit Target 40%"]
    C50 = letter["C. profit Target 50%"]

    # --- –ü—Ä–æ–ø–∏—Å—É—î–º–æ —Ñ–æ—Ä–º—É–ª–∏ –ø–æ —Ä—è–¥–∫–∞—Ö
    mult_col_letter = None
    for cell in ws[header_row]:
        if str(cell.value).strip().lower() == 'multiplier':
            mult_col_letter = cell.column_letter
            break
    for r in range(first_data_row, last_data_row + 1):
        if mult_col_letter:
            ws[f"{G}{r}"] = f"={F}{r}*{mult_col_letter}{r}"
        else:
            ws[f"{G}{r}"] = f"={F}{r}*1.3"
        ws[f"{H}{r}"] = f"={G}{r}/{E}{r}"
        ws[f"{CPCH}{r}"] = f"={K}{r}/{E}{r}"
        ws[f"{C40}{r}"] = f"={G}{r}*0.4"
        ws[f"{C50}{r}"] = f"={G}{r}*0.5"
        # L —è–∫ —Ñ–æ—Ä–º—É–ª–∞ (–ø–µ—Ä–µ–∑–∞–ø–∏—Å—É—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è, —è–∫—â–æ –±—É–ª–∏)
        ws[f"{L}{r}"] = f"={K}{r}/{G}{r}*100"

    # --- Conditional Formatting (–æ–Ω–æ–≤–ª–µ–Ω—ñ –ø—Ä–∞–≤–∏–ª–∞) ---
    first_col_letter = get_column_letter(1)
    last_col_letter = get_column_letter(ws.max_column)
    data_range = f"{first_col_letter}{first_data_row}:{last_col_letter}{last_data_row}"

    grey = PatternFill(start_color="BFBFBF", end_color="BFBFBF", fill_type="solid")
    green = PatternFill(start_color="C6EFCE", end_color="C6EFCE", fill_type="solid")
    yellow = PatternFill(start_color="FFEB9C", end_color="FFEB9C", fill_type="solid")
    red = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")

    # Dynamic threshold per GEO (–ì–∞–±–æ–Ω=59, else 39)
    try:
        GEO_col_idx = headers.get("–ì–ï–û") or headers.get("Geo") or headers.get("GEO") or headers.get("–ö—Ä–∞—ó–Ω–∞")
        GEO = get_column_letter(GEO_col_idx) if GEO_col_idx else None
    except Exception:
        GEO = None
    THR = f'IF(${GEO}{first_data_row}="–ì–∞–±–æ–Ω",59,39)' if GEO else "39"

    # Grey: E = 0
    ws.conditional_formatting.add(
        data_range,
        FormulaRule(formula=[f"${E}{first_data_row}=0"], fill=grey, stopIfTrue=True),
    )

    # Green: INT(H) <= INT(I) AND L > 39
    ws.conditional_formatting.add(
        data_range,
        FormulaRule(
            formula=[
                f"AND(${E}{first_data_row}>0,INT(${H}{first_data_row})<=INT(${I}{first_data_row}),${L}{first_data_row}>{THR})"],
            fill=green,
            stopIfTrue=True
        ),
    )

    # Yellow: (INT(H) <= INT(I)) OR (L > 39 AND H < I*1.31)
    ws.conditional_formatting.add(
        data_range,
        FormulaRule(
            formula=[
                f"AND(${E}{first_data_row}>0,OR(INT(${H}{first_data_row})<=INT(${I}{first_data_row}),AND(${L}{first_data_row}>{THR},${H}{first_data_row}<${I}{first_data_row}*1.31)))"],
            fill=yellow,
            stopIfTrue=True
        ),
    )

    # Red: (E > 0 AND H > I*1.3 AND L > 39) OR (E > 0 AND INT(H) > INT(I) AND L < 39)
    ws.conditional_formatting.add(
        data_range,
        FormulaRule(
            formula=[
                f"OR(AND(${E}{first_data_row}>0,${H}{first_data_row}>${I}{first_data_row}*1.3,${L}{first_data_row}>{THR}),AND(${E}{first_data_row}>0,INT(${H}{first_data_row})>INT(${I}{first_data_row}),${L}{first_data_row}<{THR}))"],
            fill=red,
            stopIfTrue=True
        ),
    )

    # --- Number format: 2 decimals for all numeric cells in data range
    # (–∫—Ä–∞—â–µ –∑ —Ä–æ–∑–¥—ñ–ª—é–≤–∞—á–µ–º —Ç–∏—Å—è—á)
    num_fmt = "#,##0.00"
    for row in ws.iter_rows(
            min_row=first_data_row,
            max_row=last_data_row,
            min_col=1,
            max_col=ws.max_column
    ):
        for cell in row:
            cell.number_format = num_fmt


def ask_additional_table_with_skip(message: types.Message, state: UserState):
    offer = state.offers[state.current_offer_index]
    kb = types.InlineKeyboardMarkup()
    kb.add(types.InlineKeyboardButton("–ü—Ä–æ–ø—É—Å—Ç–∏—Ç–∏ —Ü–µ–π –æ—Ñ–µ—Ä", callback_data="skip_offer"))
    bot.send_message(
        message.chat.id,
        (
            f"–ù–∞–¥—ñ—à–ª—ñ—Ç—å –¥–æ–¥–∞—Ç–∫–æ–≤—É —Ç–∞–±–ª–∏—Ü—é –¥–ª—è –æ—Ñ–µ—Ä—É:\n"
            f"<b>{offer}</b>\n\n"
            "–û—á—ñ–∫—É–≤–∞–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: <b>–ö—Ä–∞—ó–Ω–∞</b>, <b>–°—É–º–∞ –¥–µ–ø–æ–∑–∏—Ç—ñ–≤</b>.\n"
            "–ê–±–æ –Ω–∞—Ç–∏—Å–Ω—ñ—Ç—å ¬´–ü—Ä–æ–ø—É—Å—Ç–∏—Ç–∏ —Ü–µ–π –æ—Ñ–µ—Ä¬ª, —â–æ–± –Ω–µ –≤–∫–ª—é—á–∞—Ç–∏ –π–æ–≥–æ —É —Ñ—ñ–Ω–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç."
        ),
        reply_markup=kb,
    )


# ===================== ALLOCATION HELPERS =====================

def _classify_status(E: float, F: float, K: float) -> str:
    if E <= 0:
        return "Grey"
    H = 1.3 * F / E if E else float("inf")
    L = (100.0 * K) / (1.3 * F) if F else float("inf")

    # Green: E>0 and H<=9 and L>39.99
    green = (H <= H_THRESH + EPS) and (L > L_THRESH + EPS)
    if green:
        return "Green"

    # Yellow: E>0 and ((H<=9) or (L>39.99)) and not Green
    yellow = (H <= H_THRESH + EPS) or (L > L_THRESH + EPS)
    return "Yellow" if yellow else "Red"  # Red: H>9 and L<=39.99


def _fmt(v: float, suf: str = "", nan_text: str = "-") -> str:
    if not np.isfinite(v):
        return nan_text
    return f"{v:.2f}{suf}"


def build_allocation_explanation(df_source: pd.DataFrame,
                                 alloc_vec: pd.Series,
                                 budget: float,
                                 max_lines: int = 20) -> str:
    """
    –°—Ç–≤–æ—Ä—é—î —Ç–µ–∫—Å—Ç–æ–≤–∏–π –∑–≤—ñ—Ç:
      - —Å–∫—ñ–ª—å–∫–∏ –±—é–¥–∂–µ—Ç—É –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–æ —ñ –∑–∞–ª–∏—à–æ–∫
      - —Å–∫—ñ–ª—å–∫–∏ —Ä—è–¥–∫—ñ–≤ –∑–º—ñ–Ω–∏–ª–∏ —Å—Ç–∞—Ç—É—Å, —Å–∫—ñ–ª—å–∫–∏ –∂–æ–≤—Ç–∏—Ö —É –ø—ñ–¥—Å—É–º–∫—É
      - —Å–ø–∏—Å–æ–∫ —Ç–æ–ø-—Ä—è–¥–∫—ñ–≤ –∑ –∞–ª–æ–∫–∞—Ü—ñ—î—é (Offer ID / –ù–∞–∑–≤–∞ / –ì–ï–û, +—Å—É–º–∞, –Ω–æ–≤—ñ H —ñ L, —Å—Ç–∞—Ç—É—Å: –î–û ‚Üí –ü–Ü–°–õ–Ø)

    max_lines ‚Äî –æ–±–º–µ–∂–µ–Ω–Ω—è –Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –¥–µ—Ç–∞–ª—å–Ω–∏—Ö —Ä—è–¥–∫—ñ–≤ —É —Å–ø–∏—Å–∫—É (—â–æ–± –Ω–µ –ø–µ—Ä–µ–≤–∞–Ω—Ç–∞–∂—É–≤–∞—Ç–∏ —á–∞—Ç).
    """
    df = df_source.copy()
    # –Ω–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –Ω–∞–∑–≤–∏ –∫–æ–ª–æ–Ω–æ–∫ –Ω–∞ –≤—Å—è–∫ –≤–∏–ø–∞–¥–æ–∫
    df.columns = [str(c).replace("\xa0", " ").replace("\u00A0", " ").strip() for c in df.columns]

    # –í–∏—Ç—è–≥—É—î–º–æ –ø–æ—Ç—Ä—ñ–±–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ –∑ –¥–µ—Ñ–æ–ª—Ç–∞–º–∏, —è–∫—â–æ –≤—ñ–¥—Å—É—Ç–Ω—ñ
    subid = df.get("Subid", pd.Series([""] * len(df)))
    offer = df.get("Offer ID", df.get("–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É", pd.Series([""] * len(df))))
    name = df.get("–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É", pd.Series([""] * len(df)))
    geo = df.get("–ì–ï–û", pd.Series([""] * len(df)))
    E = pd.to_numeric(df.get("FTD qty", 0), errors="coerce").fillna(0.0)
    F = pd.to_numeric(df.get("Total spend", 0), errors="coerce").fillna(0.0)
    K = pd.to_numeric(df.get("Total Dep Amount", 0), errors="coerce").fillna(0.0)

    alloc = pd.to_numeric(alloc_vec, errors="coerce").reindex(df.index).fillna(0.0)
    F_new = (F + alloc)

    # –°—Ç–∞—Ç—É—Å–∏ –î–û/–ü–Ü–°–õ–Ø
    before = [_classify_status(float(E[i]), float(F[i]), float(K[i])) for i in df.index]
    after = [_classify_status(float(E[i]), float(F_new[i]), float(K[i])) for i in df.index]

    # –ú–µ—Ç—Ä–∏–∫–∏
    total_budget = float(budget)
    used = float(alloc.sum())
    left = max(0.0, total_budget - used)

    yellow_before = sum(1 for s in before if s == "Yellow")
    yellow_after = sum(1 for s in after if s == "Yellow")
    green_to_yellow = sum(1 for i in df.index if (before[i] == "Green" and after[i] == "Yellow"))

    # –ü–æ–±—É–¥–æ–≤–∞ —Å–ø–∏—Å–∫—É —Ä—è–¥–∫—ñ–≤ –∑ –∞–ª–æ–∫–∞—Ü—ñ—î—é
    rows = []
    for i in alloc.index:
        if alloc[i] <= 0:
            continue

        Ei = float(E[i]);
        Fi = float(F[i]);
        Ki = float(K[i]);
        Fni = float(F_new[i])

        # –î–û
        H_before = (1.3 * Fi / Ei) if Ei > 0 else float("inf")
        L_before = (100.0 * Ki) / (1.3 * Fi) if Fi > 0 else float("inf")

        # –ü–Ü–°–õ–Ø
        H_after = (1.3 * Fni / Ei) if Ei > 0 else float("inf")
        L_after = (100.0 * Ki) / (1.3 * Fni) if Fni > 0 else float("inf")

        line = (
            f"- {str(offer[i]) or ''} / {str(name[i]) or ''} / {str(geo[i]) or ''}: "
            f"+{alloc[i]:.2f} ‚Üí Total Spend {Fi:.2f}‚Üí{Fni:.2f}; "
            f"CPA {_fmt(H_before)}‚Üí{_fmt(H_after)}, "
            f"My deposit amount {_fmt(L_before, '%')}‚Üí{_fmt(L_after, '%')} | "
            f"{before[i]} ‚Üí {after[i]}"
        )
        rows.append((alloc[i], line))

    # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ –Ω–∞–π–±—ñ–ª—å—à–æ—é –∞–ª–æ–∫–∞—Ü—ñ—î—é —ñ –æ–±—Ä—ñ–∑–∞—î–º–æ
    rows.sort(key=lambda x: (-x[0], x[1]))
    detail_lines = [ln for _, ln in rows[:max_lines]]

    header = (
        f"–†–æ–∑–ø–æ–¥—ñ–ª –±—é–¥–∂–µ—Ç—É: {used:.2f} / {total_budget:.2f} –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–æ; –∑–∞–ª–∏—à–æ–∫ {left:.2f}\n"
        f"–ñ–æ–≤—Ç–∏—Ö –î–û/–ü–Ü–°–õ–Ø: {yellow_before} ‚Üí {yellow_after} (–∑–µ–ª.‚Üí–∂–æ–≤—Ç.: {green_to_yellow})"
    )

    if not detail_lines:
        return header + "\n\n(–ê–ª–æ–∫–∞—Ü—ñ—ó –ø–æ —Ä—è–¥–∫–∞—Ö –≤—ñ–¥—Å—É—Ç–Ω—ñ ‚Äî –±—é–¥–∂–µ—Ç –Ω–µ –±—É–ª–æ –∫—É–¥–∏ —Ä–æ–∑–ø–æ–¥—ñ–ª–∏—Ç–∏ –∑–∞ –ø—Ä–∞–≤–∏–ª–∞–º–∏.)"

    return header + "\n\n–¢–æ–ø —Ä–æ–∑–ø–æ–¥—ñ–ª—ñ–≤:\n" + "\n".join(detail_lines) + \
        ("\n\n‚Ä¶–°–ø–∏—Å–æ–∫ –æ–±—Ä—ñ–∑–∞–Ω–æ." if len(rows) > max_lines else "")


def allocate_with_openai(df: pd.DataFrame, rules_text: str, model: str | None = None) -> pd.DataFrame:
    """
    –ù–∞–¥—Å–∏–ª–∞—î —Ç–∞–±–ª–∏—Ü—é —ñ –ø—Ä–∞–≤–∏–ª–∞ –≤ OpenAI, –æ—Ç—Ä–∏–º—É—î –Ω–∞–∑–∞–¥ –æ–Ω–æ–≤–ª–µ–Ω—É —Ç–∞–±–ª–∏—Ü—é.
    –ú–æ–¥–µ–ª—å –º–∞—î –ü–û–í–ï–†–ù–£–¢–ò CSV –∑ —Ç–∏–º–∏ –∂ –∫–æ–ª–æ–Ω–∫–∞–º–∏ + –∫–æ–ª–æ–Ω–∫–∞ NEW SPEND (–∞–±–æ –æ–Ω–æ–≤–∏—Ç–∏ target-–∫–æ–ª–æ–Ω–∫—É).
    """
    if df.empty:
        raise ValueError("–ü—É—Å—Ç–∞ —Ç–∞–±–ª–∏—Ü—è –¥–ª—è –∞–ª–æ–∫–∞—Ü—ñ—ó.")

    model = model or OPENAI_MODEL
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    # 1) –î—ñ–ª–∏–º–æ –≤–µ–ª–∏–∫–∏–π DF –Ω–∞ —á–∞–Ω–∫–∏
    chunks = _split_df_by_size(df)

    updated_chunks: list[pd.DataFrame] = []

    for idx, chunk in enumerate(chunks, start=1):
        csv_in = _df_to_csv(chunk)

        system_msg = (
            "You are a meticulous data allocator. "
            "Follow the given allocation rules exactly. "
            "Return ONLY a CSV table with the SAME columns as input, "
            f"and include a numeric column '{OPENAI_OUTPUT_COLUMN}' with the recomputed spend per row. "
            "Do not add extra commentary. Use dot as decimal separator."
        )

        user_msg = (
            "Rules:\n"
            f"{rules_text}\n\n"
            "Instructions:\n"
            f"- Input table is a CSV.\n"
            f"- Keep all original columns unchanged.\n"
            f"- Add or overwrite a column named '{OPENAI_OUTPUT_COLUMN}' with the new per-row allocation (number only).\n"
            "- Return ONLY the CSV (no explanations).\n\n"
            "Input CSV:\n"
            f"{csv_in}"
        )

        resp = client.chat.completions.create(
            model=model,
            temperature=0.0,
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg},
            ],
        )

        content = resp.choices[0].message.content or ""
        csv_out = _csv_from_text(content)

        # —á–∏—Ç–∞—î–º–æ –Ω–∞–∑–∞–¥ —É DF
        try:
            out_df = pd.read_csv(io.StringIO(csv_out))
        except Exception as e:
            raise RuntimeError(f"–ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø–∞—Ä—Å–∏—Ç–∏ CSV –≤—ñ–¥ –º–æ–¥–µ–ª—ñ –Ω–∞ —á–∞–Ω–∫—É {idx}: {e}")

        # –±–∞–∑–æ–≤–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è
        missing_cols = [c for c in chunk.columns if c not in out_df.columns]
        if missing_cols:
            raise RuntimeError(f"–ú–æ–¥–µ–ª—å –Ω–µ –ø–æ–≤–µ—Ä–Ω—É–ª–∞ –≤—Å—ñ –∫–æ–ª–æ–Ω–∫–∏ (—á–∞–Ω–∫ {idx}). –í—ñ–¥—Å—É—Ç–Ω—ñ: {missing_cols}")

        if OPENAI_OUTPUT_COLUMN not in out_df.columns:
            raise RuntimeError(f"–ú–æ–¥–µ–ª—å –Ω–µ –ø–æ–≤–µ—Ä–Ω—É–ª–∞ –∫–æ–ª–æ–Ω–∫—É '{OPENAI_OUTPUT_COLUMN}' (—á–∞–Ω–∫ {idx}).")

        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ø–æ—Ä—è–¥–æ–∫ —Ä—è–¥–∫—ñ–≤: –ø—Ä–∏—î–¥–Ω–∞—î–º–æ –ø–æ —ñ–Ω–¥–µ–∫—Å—É
        # (–æ—á—ñ–∫—É—î—Ç—å—Å—è —Ç–æ–π —Å–∞–º–∏–π –ø–æ—Ä—è–¥–æ–∫ ‚Äî –∞–ª–µ –Ω–∞ –≤—Å—è–∫–∏–π –≤–∏–ø–∞–¥–æ–∫ –ø—Ä–∏–≤–µ–¥–µ–º–æ –¥–æ–≤–∂–∏–Ω–∏)
        if len(out_df) != len(chunk):
            # —è–∫ fallback ‚Äî –ø—ñ–¥—Ä—ñ–∑–∞—î–º–æ/–¥–æ–ø–æ–≤–Ω—é–≤–∞—Ç–∏ –Ω–µ –±—É–¥–µ–º–æ; –≤–≤–∞–∂–∞—î–º–æ –ø–æ–º–∏–ª–∫–æ—é
            raise RuntimeError(
                f"–†–æ–∑–º—ñ—Ä —á–∞–Ω–∫–∞ –∑–º—ñ–Ω–∏–≤—Å—è (–æ—á—ñ–∫—É–≤–∞–≤ {len(chunk)}, –æ—Ç—Ä–∏–º–∞–≤ {len(out_df)}) –Ω–∞ —á–∞–Ω–∫—É {idx}."
            )

        # –±–µ—Ä–µ–º–æ —Ç—ñ–ª—å–∫–∏ –∫–æ–ª–æ–Ω–∫—É –∑ –Ω–æ–≤–∏–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏ —ñ –∑–º–µ—Ä–¥–∂–∏–º–æ
        chunk[OPENAI_OUTPUT_COLUMN] = out_df[OPENAI_OUTPUT_COLUMN].values
        updated_chunks.append(chunk)

    # –∑–±–∏—Ä–∞—î–º–æ –Ω–∞–∑–∞–¥
    result = pd.concat(updated_chunks, axis=0)
    result.reset_index(drop=True, inplace=True)
    return result


def allocate_total_spend_alternative(
        df: pd.DataFrame,
        *,
        col_total_spend: str = "Total spend",  # F
        col_ftd_qty: str = "FTD qty",  # E
        col_cpa_target: str = "CPA Target",  # I
        col_my_deposit: str = "My deposit amount",  # L (we reuse as a scratch to show computed L_now)
        col_total_dep_amount: str = "Total Dep Amount",  # K
        col_geo: str = "–ì–ï–û",
        col_offer: str = "–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É",
        plus35_pairs: Optional[set[tuple[str, str]]] = None,  # set of (_norm_pair(offer, geo))
        in_place: bool = False,
        round_decimals: Optional[int] = 2,
        excel_path: Optional[str] = None,
        sheet_name: str = "Result",
        header_row: int = 1,
        skip_pass2: bool = False,  # if True: stop after Pass#1 + L-adjust; return leftover
        return_leftover: bool = False,  # if True: return (df, leftover_budget)
) -> Union[pd.DataFrame, tuple[pd.DataFrame, float]]:
    """
    Alternative allocation:
      1) budget = sum(F) over all rows
      2) zero all F
      3) allocate only over rows with Current='+' and E>0 (FTD>0)
    Pass#1 -> 'yellow' target
    Adjust L>THR with two caps (per-row converter depends on plus35: 100/135 or 100/130)
    Pass#2 -> 'red' ceiling (skipped if skip_pass2=True)

    If return_leftover=True, returns (df, budget_left) instead of df.
    """

    work = df if in_place else df.copy()

    # --- sanity ---
    for c in (col_total_spend, col_ftd_qty, col_cpa_target, col_my_deposit, col_total_dep_amount):
        if c not in work.columns:
            raise KeyError(f"–í—ñ–¥—Å—É—Ç–Ω—è –∫–æ–ª–æ–Ω–∫–∞: {c}")
    if col_geo not in work.columns:
        raise KeyError(f"–í—ñ–¥—Å—É—Ç–Ω—è –∫–æ–ª–æ–Ω–∫–∞ –∑ –ì–ï–û: {col_geo}")
    if col_offer not in work.columns:
        for alt in ("–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É", "–û—Ñ—Ñ–µ—Ä", "Offer", "–ù–∞–∑–≤–∞ –æ—Ñ—Ñ–µ—Ä–∞", "–ù–∞–∑–≤–∞ –æ—Ñ—Ñ–µ—Ä—É"):
            if alt in work.columns:
                col_offer = alt
                break

    # --- types ---
    for c in (col_total_spend, col_ftd_qty, col_cpa_target, col_my_deposit, col_total_dep_amount):
        work[c] = pd.to_numeric(work[c], errors="coerce").fillna(0.0)

    # --- budget & zeroing ---
    budget = float(work[col_total_spend].sum())
    if budget < 0:
        budget = 0.0
    work[col_total_spend] = 0.0

    # --- Current column & scope ---
    # We require a valid Current/current column so the scope is intentional.
    cur_col = None
    for cand in ("Current", "current"):
        if cand in work.columns:
            cur_col = cand
            break
    if cur_col is None:
        # If you prefer a fallback instead of error, replace the next line with:
        # cur_col = "Current"; work[cur_col] = "+"
        raise ValueError("–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∫–æ–ª–æ–Ω–∫—É 'Current'/'current'. –°–ø–æ—á–∞—Ç–∫—É –¥–æ–¥–∞–π—Ç–µ —ó—ó (–∑ '+' –¥–ª—è –ø–æ—Ç—Ä—ñ–±–Ω–∏—Ö —Ä—è–¥–∫—ñ–≤).")

    mask_current = (work[cur_col].astype(str).str.strip() == "+")
    mask_ftd = (work[col_ftd_qty] > 0)
    mask_scope = (mask_current & mask_ftd)

    if not bool(mask_scope.any()):
        # If you prefer to fallback silently to all E>0 rows, replace 'raise' with:
        # mask_scope = mask_ftd
        # (and maybe log a warning). For now, we error to avoid silent all-zero allocations.
        raise ValueError(
            "–ù–µ–º–∞—î —Ä—è–¥–∫—ñ–≤ –¥–ª—è –∞–ª–æ–∫–∞—Ü—ñ—ó: –ø–æ—Ç—Ä—ñ–±–Ω—ñ Current='+' —Ç–∞ FTD qty > 0. "
            "–ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –∫–æ–ª–æ–Ω–∫—É Current —Ç–∞ –∑–Ω–∞—á–µ–Ω–Ω—è FTD."
        )

    # --- constants ---
    CONV = 100.0 / 130.0  # used in Pass#1 and red ceiling (per your spec)
    MULT_Y_HI = 1.3
    MULT_Y_LO = 1.1
    MULT_CPA_Y = 1.3
    MULT_RED = 1.8

    # threshold per GEO
    geo_raw = work[col_geo].astype(str).str.strip().fillna("")
    L_threshold_series = np.where(geo_raw.eq("–ì–∞–±–æ–Ω"), 59.0, 39.0)

    # Use original L (My deposit amount) to choose yellow multiplier in Pass#1
    L_for_threshold = pd.to_numeric(df[col_my_deposit], errors="coerce").fillna(0.0).clip(lower=0)

    # ---------------- Pass#1: 'yellow' ----------------
    idx_pass1 = work.loc[mask_scope].sort_values(by=col_ftd_qty, ascending=True).index
    for i in idx_pass1:
        if budget <= 0:
            break
        E = float(work.at[i, col_ftd_qty])
        I = float(work.at[i, col_cpa_target])
        Lthr_val = float(L_for_threshold.at[i])
        thr_i = float(L_threshold_series[work.index.get_loc(i)])

        mult = MULT_Y_HI if Lthr_val >= thr_i else MULT_Y_LO
        target_F = E * I * mult * CONV
        add = min(target_F, budget)
        work.at[i, col_total_spend] = add
        budget -= add

    # -------- Recompute L, adjust where L>THR with 2 caps --------
    # L_now = (K / (F*1.3)) * 100
    G_now = work[col_total_spend] * 1.3
    with np.errstate(divide='ignore', invalid='ignore'):
        L_now = np.where(G_now > 0, (work[col_total_dep_amount] / G_now) * 100.0, np.inf)
    work[col_my_deposit] = L_now  # show in L column for visibility

    mask_adjust = mask_scope.values & (L_now > L_threshold_series)

    # === per-row CONV for caps if plus35 ===
    if plus35_pairs:
        def _n(s: str) -> str:
            s = str(s or "").strip().lower()
            s = s.replace("‚Äô", "'").replace("`", "'").replace("‚Äì", "-").replace("‚Äî", "-")
            s = re.sub(r"\s+", " ", s)
            return s

        offer_norm = work[col_offer].map(_n) if col_offer in work.columns else pd.Series([""] * len(work),
                                                                                         index=work.index)
        geo_norm = work[col_geo].map(_n)
        is_plus35 = np.array([(o, g) in plus35_pairs for o, g in zip(offer_norm, geo_norm)], dtype=bool)
    else:
        is_plus35 = np.zeros(len(work), dtype=bool)

    # per-row converters for the caps ONLY (as requested)
    CONV_CAP = np.where(is_plus35, 100.0 / 135.0, 100.0 / 130.0)

    if mask_adjust.any():
        K = work[col_total_dep_amount].values
        E = work[col_ftd_qty].values
        I = work[col_cpa_target].values
        TH = L_threshold_series

        # caps honor plus35 via CONV_CAP
        F_cap_dep = (K / TH * 100.0) * CONV_CAP
        F_cap_cpa = (E * I * MULT_CPA_Y) * CONV_CAP
        F_target = np.minimum(F_cap_dep, F_cap_cpa)

        curF = work[col_total_spend].values
        adj = mask_adjust

        # raise where needed (consume budget)
        need_up_mask = adj & (F_target > curF)
        delta_up = F_target - curF
        need_up_total = float(delta_up[need_up_mask].sum())
        if need_up_total > 0 and budget > 0:
            ratio = min(1.0, budget / need_up_total)
            inc = np.zeros_like(curF, dtype=float)
            inc[need_up_mask] = delta_up[need_up_mask] * ratio
            curF += inc
            budget -= float(inc.sum())

        # lower where needed (free budget)
        need_down_mask = adj & (F_target < curF)
        freed = float((curF[need_down_mask] - F_target[need_down_mask]).sum())
        if freed > 0:
            curF[need_down_mask] = F_target[need_down_mask]
            budget += freed

        work[col_total_spend] = curF

        # refresh L display
        G_now = work[col_total_spend] * 1.3
        with np.errstate(divide='ignore', invalid='ignore'):
            L_now = np.where(G_now > 0, (work[col_total_dep_amount] / G_now) * 100.0, np.inf)
        work[col_my_deposit] = L_now

    # ---------------- Pass#2: 'red' ceiling ----------------
    if (not skip_pass2) and budget > 0:
        idx_pass2 = work.loc[mask_scope].sort_values(by=col_total_spend, ascending=True).index
        for i in idx_pass2:
            if budget <= 0:
                break
            E = float(work.at[i, col_ftd_qty])
            I = float(work.at[i, col_cpa_target])
            red_cap = E * I * MULT_RED * CONV
            curF = float(work.at[i, col_total_spend])
            need = max(0.0, red_cap - curF)
            if need <= 0:
                continue
            add = min(need, budget)
            work.at[i, col_total_spend] = curF + add
            budget -= add

    # rounding
    if round_decimals is not None:
        work[col_total_spend] = work[col_total_spend].round(round_decimals)

    # write excel if requested
    if excel_path:
        with ExcelWriter(excel_path, engine="openpyxl", mode="w") as writer:
            work.to_excel(writer, sheet_name=sheet_name, index=False)
            ws = writer.book[sheet_name]
            first_data_row = header_row + 1
            last_data_row = header_row + len(work)
            inject_formulas_and_cf(ws, header_row=header_row, first_data_row=first_data_row,
                                   last_data_row=last_data_row)
            # (optional) here you can re-write 'Total+%' per row to 1.35 for plus35 pairs if you need
            writer._save()

    return (work, budget) if return_leftover else work


def compute_optimal_allocation(df: pd.DataFrame, budget: float) -> Tuple[pd.DataFrame, str, pd.Series]:
    """
    –ù–æ–≤–∞ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å:
      A) –°–ø–æ—á–∞—Ç–∫—É –Ω–∞–º–∞–≥–∞—î–º–æ—Å—å –º—ñ–Ω—ñ–º–∞–ª—å–Ω–æ –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ GREEN -> YELLOW (–¥–æ—Ç—Ä–∏–º—É—é—á–∏—Å—å CPA<=CPA_CAP).
      B) –Ø–∫—â–æ –∑–∞–ª–∏—à–∏–≤—Å—è –±—é–¥–∂–µ—Ç ‚Äî –Ω–∞—Å–∏—á—É—î–º–æ YELLOW –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ, –∞–ª–µ —Ç–∞–∫, —â–æ–± –≤–æ–Ω–∏ –∑–∞–ª–∏—à–∞–ª–∏—Å—å YELLOW (—ñ CPA<=CPA_CAP).

    –ü–æ–∑–Ω–∞—á–µ–Ω–Ω—è:
      E = FTD qty
      F = Total spend
      K = Total Dep Amount

    –ú–µ–∂—ñ/–ø–æ—Ö—ñ–¥–Ω—ñ:
      F_at_H = H_THRESH * E / 1.3
      F_at_L = (100 * K) / (1.3 * L_THRESH)  # L == L_THRESH –ø—Ä–∏ —Ç–∞–∫–æ–º—É F
      F_cap  = CPA_CAP * E / 1.3
    """
    dfw = df.copy()

    # –ß–∏—Å–ª–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏
    E = pd.to_numeric(dfw["FTD qty"], errors="coerce").fillna(0.0)
    F = pd.to_numeric(dfw["Total spend"], errors="coerce").fillna(0.0)
    K = pd.to_numeric(dfw["Total Dep Amount"], errors="coerce").fillna(0.0)

    # –ü–æ—Ç–æ—á–Ω—ñ H, L
    with np.errstate(divide='ignore', invalid='ignore'):
        H = 1.3 * F / E.replace(0, np.nan)
        L = 100.0 * K / (1.3 * F.replace(0, np.nan))

    # –ú–µ–∂—ñ
    F_at_H = H_THRESH * E / 1.3
    F_at_L = (100.0 * K) / (1.3 * L_THRESH)
    F_cap = CPA_CAP * E / 1.3

    # –ú–∞—Å–∫–∏ —Å—Ç–∞—Ç—É—Å—ñ–≤ (—Å—Ç—Ä–æ–≥–æ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ –¥–æ –ø—Ä–∞–≤–∏–ª/Excel)
    grey_mask = (E <= 0)
    green_mask = (~grey_mask) & (H <= H_THRESH + EPS) & (L > L_THRESH + EPS)
    yellow_mask = (~grey_mask) & ((H <= H_THRESH + EPS) | (L > L_THRESH + EPS)) & (~green_mask)
    # red_mask   = (~grey_mask) & (~green_mask) & (~yellow_mask)  # –Ω–µ –ø–æ—Ç—Ä—ñ–±–µ–Ω —è–≤–Ω–æ

    alloc = pd.Series(0.0, index=dfw.index, dtype=float)
    rem = float(budget) if budget and budget > 0 else 0.0

    # -------------------------------
    # A) GREEN -> YELLOW (–º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π spend)
    # -------------------------------
    # –ö–∞–Ω–¥–∏–¥–∞—Ç–∏ —Ü—ñ–ª—å–æ–≤–∏—Ö F:
    #   - –ø–µ—Ä–µ—Ç–Ω—É—Ç–∏ –º–µ–∂—É H: F_cross_H = F_at_H + EPS_YEL (—Ä–æ–±–∏—Ç—å H —Ç—Ä–æ—Ö–∏ > H_THRESH)
    #   - –ø–µ—Ä–µ—Ç–Ω—É—Ç–∏ –º–µ–∂—É L: F_cross_L = F_at_L + EPS_YEL (—Ä–æ–±–∏—Ç—å L —Ç—Ä–æ—Ö–∏ < L_THRESH)
    F_cross_H = F_at_H + EPS_YEL
    F_cross_L = F_at_L + EPS_YEL

    # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π F, —è–∫–∏–π –∑–ª–∞–º–∞–≤ "–∑–µ–ª–µ–Ω—ñ—Å—Ç—å", –∞–ª–µ –Ω–µ —Ä–æ–±–∏—Ç—å —Ä—è–¥–æ–∫ "—á–µ—Ä–≤–æ–Ω–∏–º" —ñ –Ω–µ –ø–µ—Ä–µ–≤–∏—â—É—î CPA cap.
    candidates = pd.DataFrame({
        "F_now": F,
        "F_cap": F_cap,
        "F_cross_H": F_cross_H,
        "F_cross_L": F_cross_L,
        "E": E,
        "K": K
    })

    # –î–ª—è –∫–æ–∂–Ω–æ–≥–æ green –æ–±—á–∏—Å–ª—é—î–º–æ –Ω–∞–π–º–µ–Ω—à—É –¥–æ–ø—É—Å—Ç–∏–º—É —Ü—ñ–ª—å F_target
    F_target = F.copy()

    for i in candidates[green_mask].index:
        Fi = float(candidates.at[i, "F_now"])
        Fcap = float(candidates.at[i, "F_cap"])
        Fh = float(candidates.at[i, "F_cross_H"])
        Fl = float(candidates.at[i, "F_cross_L"])
        Ei = float(E.at[i])
        Ki = float(K.at[i])

        # –û–±–∏–¥–≤–∞ –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω—ñ —Ü—ñ–ª—ñ –≤ –º–µ–∂–∞—Ö CPA?
        options = []
        for Ft in (Fh, Fl):
            if np.isfinite(Ft) and Ft > Fi + EPS and Ft <= Fcap + EPS:
                # –ü–µ—Ä–µ–≤—ñ—Ä–∏–º–æ, —â–æ Ft –Ω–µ —Ä–æ–±–∏—Ç—å —Ä—è–¥–æ–∫ "—á–µ—Ä–≤–æ–Ω–∏–º"
                Ht = 1.3 * Ft / Ei if Ei > 0 else float("inf")
                Lt = (100.0 * Ki) / (1.3 * Ft) if Ft > 0 else float("inf")
                is_red = (Ht > H_THRESH + EPS) and (Lt <= L_THRESH + EPS)
                if not is_red:
                    options.append(Ft)

        if options:
            F_target.at[i] = min(options)  # –Ω–∞–π–º–µ–Ω—à–∞ —Ü—ñ–Ω–∞ –ø–µ—Ä–µ—Ö–æ–¥—É
        else:
            # –Ω–µ–º–æ–∂–ª–∏–≤–æ –ª–µ–≥–∞–ª—å–Ω–æ –∑—Ä–æ–±–∏—Ç–∏ –∂–æ–≤—Ç–∏–º ‚Äî –∑–∞–ª–∏—à–∞—î–º–æ —è–∫ —î
            F_target.at[i] = Fi

    need_delta = (F_target - F).clip(lower=0.0)

    # –†–æ–∑–ø–æ–¥—ñ–ª: –∑–∞ –∑—Ä–æ—Å—Ç–∞–Ω–Ω—è–º –ø–æ—Ç—Ä—ñ–±–Ω–æ—ó –¥–µ–ª—å—Ç–∏
    for i in need_delta[green_mask].sort_values(ascending=True).index:
        if rem <= 1e-9:
            break
        need = float(need_delta.at[i])
        if need <= 0:
            continue
        take = min(rem, need)
        alloc.at[i] += take
        rem -= take

    # -------------------------------
    # B) –ù–∞—Å–∏—á–µ–Ω–Ω—è YELLOW, —â–æ–± –ª–∏—à–∞–ª–∏—Å—å YELLOW (CPA<=cap)
    # -------------------------------
    if rem > 1e-9:
        # –ü–µ—Ä–µ—Ä–∞—Ö—É–≤–∞—Ç–∏ F –ø—ñ—Å–ª—è –∫—Ä–æ–∫—É A
        F_mid = F + alloc
        with np.errstate(divide='ignore', invalid='ignore'):
            H_mid = 1.3 * F_mid / E.replace(0, np.nan)
            L_mid = 100.0 * K / (1.3 * F_mid.replace(0, np.nan))

        # –¢—ñ, —Ö—Ç–æ –∑–∞—Ä–∞–∑ –∂–æ–≤—Ç—ñ (–≤–∫–ª—é—á–Ω–æ –∑ –Ω–æ–≤–∏–º–∏ –∑ –∫—Ä–æ–∫—É A)
        is_green_mid = (~(E <= 0)) & (H_mid <= H_THRESH + EPS) & (L_mid > L_THRESH + EPS)
        is_yellow_mid = (~(E <= 0)) & (((H_mid <= H_THRESH + EPS) | (L_mid > L_THRESH + EPS)) & (~is_green_mid))

        # –ú–µ–∂–∞ "–∑–∞–ª–∏—à–∏—Ç–∏—Å—å –∂–æ–≤—Ç–∏–º": –¥–æ max(F_at_H, F_at_L - EPS_YEL), —Ç–∞ —â–µ –π –Ω–µ –ø–µ—Ä–µ–≤–∏—â–∏—Ç–∏ cap
        F_yellow_limit_base = pd.Series(np.maximum(F_at_H, F_at_L - EPS_YEL), index=dfw.index)
        F_yellow_limit_final = pd.Series(np.minimum(F_yellow_limit_base, F_cap), index=dfw.index).fillna(0.0)

        headroom = (F_yellow_limit_final - F_mid).clip(lower=0.0)

        # Greedy –∑–∞ —Å–ø–∞–¥–∞–Ω–Ω—è–º headroom
        for i in headroom[is_yellow_mid].sort_values(ascending=False).index:
            if rem <= 1e-9:
                break
            give = float(min(rem, headroom.at[i]))
            if give <= 0:
                continue
            alloc.at[i] += give
            rem -= give

    # –ü–Ü–î–°–£–ú–û–ö
    F_final = F + alloc
    with np.errstate(divide='ignore', invalid='ignore'):
        H_final = 1.3 * F_final / E.replace(0, np.nan)
        L_final = 100.0 * K / (1.3 * F_final.replace(0, np.nan))

    still_green = (E > 0) & (H_final <= H_THRESH + EPS) & (L_final > L_THRESH + EPS)
    still_yellow = (E > 0) & (((H_final <= H_THRESH + EPS) | (L_final > L_THRESH + EPS)) & (~still_green))

    kept_yellow = int(still_yellow.sum())
    total_posE = int((E > 0).sum())

    dfw["Allocated extra"] = alloc
    dfw["New Total spend"] = F_final
    dfw["Will be yellow"] = ["Yes" if x else "No" for x in still_yellow]

    summary = (
        f"–ë—é–¥–∂–µ—Ç: {budget:.2f}\n"
        f"–ñ–æ–≤—Ç–∏—Ö –ø—ñ—Å–ª—è —Ä–æ–∑–ø–æ–¥—ñ–ª—É: {kept_yellow}/{total_posE}\n"
        f"–ü—Ä–∞–≤–∏–ª–∞: —Å–ø–æ—á–∞—Ç–∫—É –ø–µ—Ä–µ–≤–æ–¥–∏–º–æ –∑–µ–ª–µ–Ω—ñ –≤ –∂–æ–≤—Ç—ñ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–º spend (CPA‚â§{CPA_CAP:g}), "
        f"–ø–æ—Ç—ñ–º –Ω–∞—Å–∏—á—É—î–º–æ –∂–æ–≤—Ç—ñ –≤ –º–µ–∂–∞—Ö –∂–æ–≤—Ç–æ–≥–æ (H‚â§{H_THRESH:g} –∞–±–æ L>{L_THRESH:.2f}, CPA‚â§{CPA_CAP:g})."
    )
    return dfw, summary, alloc


def write_result_like_excel_with_new_spend(bio: io.BytesIO, df_source: pd.DataFrame, new_total_spend: pd.Series):
    """
    Build an Excel sheet identical to result.xlsx structure:
    Columns (A..P):
      A Subid | B Offer ID | C –ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É | D –ì–ï–û | E FTD qty | F Total spend | G Total+% | H CPA | I CPA Target |
      J –°P/–ß | K Total Dep Amount | L My deposit amount | M C. profit Target 40% | N C. profit Target 50% | O CAP | P –û—Å—Ç–∞—Ç–æ–∫ CAP
    Uses new_total_spend for column F, then writes the same formulas, formats and conditional formatting.
    """
    final_cols = [
        "Subid", "Offer ID", "–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É", "–ì–ï–û",
        "FTD qty", "Total spend", "Total+%", "CPA", "CPA Target", "–°P/–ß",
        "Total Dep Amount", "My deposit amount", "C. profit Target 40%", "C. profit Target 50%",
        "CAP", "–û—Å—Ç–∞—Ç–æ–∫ CAP", "Current"
    ]

    # Start from source, ensure all columns exist
    df_out = df_source.copy()
    # normalize column names just in case
    df_out.columns = [str(c).replace("\xa0", " ").replace("\u00A0", " ").strip() for c in df_out.columns]

    # Coerce numbers
    df_out["FTD qty"] = pd.to_numeric(df_out.get("FTD qty", 0), errors="coerce").fillna(0)
    df_out["Total spend"] = pd.to_numeric(df_out.get("Total spend", 0), errors="coerce").fillna(0.0)
    df_out["Total Dep Amount"] = pd.to_numeric(df_out.get("Total Dep Amount", 0.0), errors="coerce").fillna(0.0)

    # Apply new spend
    # align by index; if shapes don't match, reindex new_total_spend to df_out
    new_total_spend = pd.to_numeric(new_total_spend, errors="coerce").fillna(0.0)
    new_total_spend = new_total_spend.reindex(df_out.index).fillna(0.0)
    df_out["Total spend"] = (df_out["Total spend"] + new_total_spend).round(2)

    # Ensure missing columns exist as blanks
    for col in final_cols:
        if col not in df_out.columns:
            df_out[col] = ""

    # Reorder
    df_out = df_out[final_cols].copy()

    # Round numeric display columns
    df_out["FTD qty"] = pd.to_numeric(df_out["FTD qty"], errors="coerce").fillna(0).astype(int)
    for col in ["Total spend", "Total Dep Amount"]:
        df_out[col] = pd.to_numeric(df_out[col], errors="coerce").round(2)

    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        df_out.to_excel(writer, index=False, sheet_name="Result")
        wb = writer.book
        ws = writer.sheets["Result"]

        from openpyxl.styles import PatternFill, Alignment, Font
        from openpyxl.formatting.rule import FormulaRule

        first_row = 2
        last_row = ws.max_row

        # Re-insert formulas (same as send_final_table)
        for r in range(first_row, last_row + 1):
            offer_val = ws[f"C{r}"].value
            geo_val = ws[f"D{r}"].value
            mul = 1.3
            if plus35_pairs:
                try:
                    if _norm_pair(offer_val, geo_val) in plus35_pairs:
                        mul = 1.35
                except Exception:
                    pass
            ws[f"G{r}"].value = f"=F{r}*{mul}"  # Total+%
            ws[f"H{r}"].value = f"=IFERROR(G{r}/E{r},\"\")"  # CPA
            ws[f"I{r}"].value = cpa_target_for_geo(ws[f"D{r}"].value)  # CPA Target
            ws[f"J{r}"].value = f"=IFERROR(K{r}/E{r},\"\")"  # –°P/–ß
            ws[f"L{r}"].value = f"=IFERROR(K{r}/G{r}*100,0)"  # My deposit amount
            ws[f"M{r}"].value = f"=G{r}*0.4"  # Profit 40%
            ws[f"N{r}"].value = f"=G{r}*0.5"  # Profit 50%

        # Header styling
        for col in range(1, 17):  # A..P
            ws.cell(row=1, column=col).font = Font(bold=True)
            ws.cell(row=1, column=col).alignment = Alignment(horizontal="center")

        # Widths
        widths = {"A": 10, "B": 12, "C": 22, "D": 16, "E": 10, "F": 14, "G": 12, "H": 10, "I": 12, "J": 10, "K": 16,
                  "L": 18, "M": 18, "N": 18, "O": 12, "P": 16}
        for col, w in widths.items():
            ws.column_dimensions[col].width = w

        # Number formats (2 decimals for F,G,H,J,K,L,M,N; E as integer)
        for r in range(first_row, last_row + 1):
            ws[f"E{r}"].number_format = "0"
        two_dec_cols = ["F", "G", "H", "J", "K", "L", "M", "N"]
        for col in two_dec_cols:
            for r in range(first_row, last_row + 1):
                ws[f"{col}{r}"].number_format = "0.00"

        # Conditional formatting ‚Äî SAME rules/colors
        data_range = f"A{first_row}:P{last_row}"
        grey = PatternFill("solid", fgColor="BFBFBF")
        green = PatternFill("solid", fgColor="C6EFCE")
        yellow = PatternFill("solid", fgColor="FFEB9C")
        red = PatternFill("solid", fgColor="FFC7CE")

        THR2 = 'IF($D2="–ì–∞–±–æ–Ω",59,39)'

        # Grey: E = 0
        ws.conditional_formatting.add(
            data_range,
            FormulaRule(formula=["$E2=0"], fill=grey, stopIfTrue=True)
        )

        # Green: INT(H) <= INT(I) AND L > 39
        ws.conditional_formatting.add(
            data_range,
            FormulaRule(formula=[f"AND($E2>0,INT($H2)<=INT($I2),$L2>{THR2})"], fill=green, stopIfTrue=True)
        )

        # Yellow: (INT(H) <= INT(I)) OR (L > 39 AND H < I*1.31)
        ws.conditional_formatting.add(
            data_range,
            FormulaRule(formula=[f"AND($E2>0,OR(INT($H2)<=INT($I2),AND($L2>{THR2},$H2<$I2*1.31)))"], fill=yellow,
                        stopIfTrue=True)
        )

        # Red: (E > 0 AND H > I*1.3 AND L > 39) OR (E > 0 AND INT(H) > INT(I) AND L < 39)
        ws.conditional_formatting.add(
            data_range,
            FormulaRule(
                formula=[f"OR(AND($E2>0,$H2>$I2*1.3,$L2>{THR2}),AND($E2>0,INT($H2)>INT($I2),$L2<{THR2}))"],
                fill=red,
                stopIfTrue=True
            )
        )


def _run_alternative_and_send(chat_id: int, state: UserState):
    """
    Runs allocate_total_spend_alternative with optional pairs
    and sends 'allocation_alternative.xlsx' back to the user.
    Resets phase to WAIT_MAIN at the end.
    """
    if state.alloc_df is None:
        bot.send_message(chat_id, "–ù–µ–º–∞—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ—ó —Ç–∞–±–ª–∏—Ü—ñ Result. –°–ø—Ä–æ–±—É–π—Ç–µ /allocate —â–µ —Ä–∞–∑.")
        state.phase = "WAIT_MAIN"
        return

    out_df, leftover_budget = allocate_total_spend_alternative(
        state.alloc_df,
        col_total_spend="Total spend",
        col_ftd_qty="FTD qty",
        col_cpa_target="CPA Target",
        col_my_deposit="My deposit amount",
        col_total_dep_amount="Total Dep Amount",
        col_geo="–ì–ï–û",
        col_offer="–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É",
        plus35_pairs=getattr(state, 'plus35_pairs', None),
        excel_path="Result.xlsx",
        sheet_name="Result",
        header_row=1,
        return_leftover=True,
    )

    try:
        with open("Result.xlsx", "rb") as f:
            bot.send_document(
                chat_id,
                f,
                visible_file_name="allocation_alternative.xlsx",
                caption=(
                    "–ì–æ—Ç–æ–≤–æ: –∞–ª–æ–∫–∞—Ü—ñ—è –∑–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∏–º —Ä–µ–∂–∏–º–æ–º"
                )
            )
            bot.send_message(chat_id, f'–ó–∞–ª–∏—à–æ–∫ –±—é–¥–∂–µ—Ç—É –ø—ñ—Å–ª—è —Ä–æ–∑–ø–æ–¥—ñ–ª—É: $<b>{leftover_budget:,.2f}</b>',
                             parse_mode="HTML")
    except Exception as e:
        bot.send_message(chat_id, f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –≤—ñ–¥–ø—Ä–∞–≤–∏—Ç–∏ Excel: <code>{e}</code>", parse_mode="HTML")
    finally:
        # reset minimal allocate state
        state.phase = "WAIT_MAIN"
        state.alloc_df = None


# ===================== PAIR HELPERS =====================
def _norm_pair(offer: str, geo: str) -> tuple[str, str]:
    """
    –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–∞—Ä–∏ (–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É, –ì–ï–û):
    - lowercase
    - strip spaces
    - –∑–∞–º—ñ–Ω–∞ —Ä—ñ–∑–Ω–∏—Ö –∞–ø–æ—Å—Ç—Ä–æ—Ñ—ñ–≤, –¥–µ—Ñ—ñ—Å—ñ–≤, –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏—Ö –ª–∞–ø–æ–∫
    - –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è unicode ( º ‚Üí ')
    """

    def clean(s: str) -> str:
        if not s:
            return ""
        s = str(s).strip().lower()
        s = unicodedata.normalize("NFKC", s)
        s = s.replace("‚Äô", "'").replace(" º", "'").replace("`", "'")
        s = re.sub(r"[\u2013\u2014]", "-", s)  # em/en dash ‚Üí -
        s = re.sub(r"\s+", " ", s)
        return s

    return (clean(offer), clean(geo))


def _mark_current(offer: str, geo: str, current_pairs: set[tuple[str, str]] | None) -> str:
    if not current_pairs:
        return "-"  # —è–∫—â–æ current.xlsx –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ ‚Äî –¥–µ—Ñ–æ–ª—Ç–Ω–æ '-'
    return "+" if _norm_pair(offer, geo) in current_pairs else "-"


def _extract_pairs_df(df: pd.DataFrame) -> set[tuple[str, str]]:
    lower = {str(c).strip().lower(): c for c in df.columns}
    geo_col = lower.get('–≥–µ–æ') or lower.get('geo')
    offer_col = lower.get('–Ω–∞–∑–≤–∞ –æ—Ñ—Ñ–µ—Ä—É') or lower.get('–Ω–∞–∑–≤–∞ –æ—Ñ–µ—Ä—É') or lower.get('offer') or lower.get('offer id')
    if not geo_col or not offer_col:
        raise ValueError("–û—á—ñ–∫—É—é –¥–≤—ñ –∫–æ–ª–æ–Ω–∫–∏: '–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É' —ñ '–ì–ï–û' (–∞–±–æ '–ì–µ–æ').")
    pairs = set()
    for _, row in df[[offer_col, geo_col]].dropna().iterrows():
        pairs.add(_norm_pair(row[offer_col], row[geo_col]))
    return pairs


def build_en_to_uk_preferred(uk_to_en: Dict[str, str]) -> Dict[str, str]:
    """
    –ü–æ–±—É–¥—É–≤–∞—Ç–∏ EN -> UA –º–∞–ø—É –∑ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–æ–º —É–∫—Ä–∞—ó–Ω—Å—å–∫–∏—Ö –Ω–∞–∑–≤ —ñ–∑ –≤–∞—à–æ—ó UA-–º–∞–ø–∏.
    –ö–ª—é—á—ñ —É normalize_text, –∑–Ω–∞—á–µ–Ω–Ω—è ‚Äî —è–∫ —î (–∫—Ä–∞—Å–∏–≤—ñ UA –Ω–∞–∑–≤–∏).
    """
    en_to_uk: Dict[str, str] = {}
    for ua_raw, en_raw in uk_to_en.items():
        ua_key = normalize_text(ua_raw)
        en_key = normalize_text(en_raw)
        # –ü–µ—Ä—à–∏–π, —Ö—Ç–æ –∑–∞–ø–∏—à–µ, –ø–µ—Ä–µ–º–æ–∂–µ (—Å—Ç–∞–±—ñ–ª—å–Ω–∞ –ø–µ—Ä–µ–≤–∞–≥–∞)
        en_to_uk.setdefault(en_key, ua_raw)
    return en_to_uk


def unite_ua_ru_rows(
        df: pd.DataFrame,
        *,
        country_col: str = "–ì–ï–û",
        total_spend_col: str = "Total spend",
        offer_col: str = "–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É",
) -> pd.DataFrame:
    """
    –û–±'—î–¥–Ω—É—î —Ä—è–¥–∫–∏ UA/RU –∫—Ä–∞—ó–Ω–∏ –¢–Ü–õ–¨–ö–ò –≤ –º–µ–∂–∞—Ö –æ–¥–Ω–æ–≥–æ –æ—Ñ—Ñ–µ—Ä–∞:
      –∫–ª—é—á = (offer_col, canonical_en(country))
    –°—É–º—É—î–º–æ –õ–ò–®–ï Total spend (–≤—Å–µ —ñ–Ω—à–µ ‚Äî —è–∫ —É –ø–µ—Ä—à–æ–º—É —Ä—è–¥–∫—É –≥—Ä—É–ø–∏).
    –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –ø–æ–≤–Ω—É —Ç–∞–±–ª–∏—Ü—é –∑ —É—Å—ñ–º–∞ –Ω–∞—è–≤–Ω–∏–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏ —É –≤—Ö—ñ–¥–Ω–æ–º—É df.
    """

    # –ú–∞–ø–∏
    uk_to_en = build_country_map_uk_to_en()
    canonical = build_country_canonical()
    try:
        ru_to_en = build_country_map_ru_to_en()
    except NameError:
        ru_to_en = None

    en_to_uk = build_en_to_uk_preferred(uk_to_en)

    work = df.copy()

    # –ü—ñ–¥—Ö–æ–ø–∏—Ç–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ñ –Ω–∞–∑–≤–∏ —Å—É–º–æ–≤–æ—ó –∫–æ–ª–æ–Ω–∫–∏ (BUDG –∫–µ–π—Å)
    if total_spend_col not in work.columns and "–ó–∞–≥–∞–ª—å–Ω—ñ –≤–∏—Ç—Ä–∞—Ç–∏" in work.columns:
        total_spend_col = "–ó–∞–≥–∞–ª—å–Ω—ñ –≤–∏—Ç—Ä–∞—Ç–∏"

    if country_col not in work.columns:
        raise KeyError(f"–í—ñ–¥—Å—É—Ç–Ω—è –∫–æ–ª–æ–Ω–∫–∞ –∫—Ä–∞—ó–Ω–∏: {country_col}")
    if offer_col not in work.columns:
        raise KeyError(f"–í—ñ–¥—Å—É—Ç–Ω—è –∫–æ–ª–æ–Ω–∫–∞ –æ—Ñ—Ñ–µ—Ä–∞: {offer_col}")

    # –ö–∞–Ω–æ–Ω EN –∫—Ä–∞—ó–Ω–∏ (UA->EN, RU->EN, canonical)
    work["__canon_en__"] = work[country_col].apply(
        lambda x: to_canonical_en(x, uk_to_en, canonical, ru_to_en)
    )

    # –ù–æ—Ä–º-–∫–ª—é—á –¥–ª—è –≥—Ä—É–ø—É–≤–∞–Ω–Ω—è
    def _nz(s):
        return normalize_text(s)

    work["__canon_key__"] = work["__canon_en__"].map(_nz)
    work["__offer_key__"] = work[offer_col].astype(str).map(_nz)

    # –ê–≥–≥—Ä–µ–≥–∞—Ü—ñ—è: Total spend -> sum; —Ä–µ—à—Ç–∞ -> first
    agg_dict = {total_spend_col: "sum"}
    # –∑–±–µ—Ä—ñ–≥–∞—î–º–æ –≤—Å—ñ —ñ–Ω—à—ñ –∫–æ–ª–æ–Ω–∫–∏ (–≤–∫–ª—é—á–Ω–æ –∑ —Ñ–æ—Ä–º—É–ª—å–Ω–∏–º–∏, –∑–Ω–∞—á–µ–Ω–Ω—è –≤—ñ–∑—å–º–µ–º–æ –∑ –ø–µ—Ä—à–æ–≥–æ —Ä—è–¥–∫–∞)
    for c in work.columns:
        if c not in (total_spend_col, "__canon_en__", "__canon_key__", "__offer_key__"):
            agg_dict.setdefault(c, "first")

    out = (
        work.groupby(["__offer_key__", "__canon_key__"], as_index=False)
        .agg(agg_dict)
    )

    # –í—ñ–¥–Ω–æ–≤–ª—é—î–º–æ —É–∫—Ä–∞—ó–Ω—Å—å–∫—É –Ω–∞–∑–≤—É –∫—Ä–∞—ó–Ω–∏: –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç –∑ UA-–º–∞–ø–∏, —ñ–Ω–∞–∫—à–µ –±–µ—Ä–µ–º–æ –ø–µ—Ä—à—É –∑ –≥—Ä—É–ø–∏
    def _uk_name(row):
        ck = row["__canon_key__"]
        if ck in en_to_uk:
            return en_to_uk[ck]
        # –∑–Ω–∞–π—Ç–∏ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—É –∑ –≥—Ä—É–ø–∏
        mask = (work["__canon_key__"] == ck) & (work["__offer_key__"] == row["__offer_key__"])
        sample = work.loc[mask, country_col].dropna().astype(str)
        return sample.iloc[0] if not sample.empty else row.get("__canon_en__", "")

    out[country_col] = out.apply(_uk_name, axis=1)

    # –ü—Ä–∏–±—Ä–∞—Ç–∏ —Å–ª—É–∂–±–æ–≤—ñ
    for c in ("__canon_en__", "__canon_key__", "__offer_key__"):
        if c in out.columns:
            out.drop(columns=[c], inplace=True)

    # –ü—Ä–∏–≤–µ—Å—Ç–∏ —á–∏—Å–ª–æ
    out[total_spend_col] = pd.to_numeric(out[total_spend_col], errors="coerce").fillna(0).round(2)

    return out


# ===================== BOT HANDLERS =====================

@bot.message_handler(commands=["start", "help"])
@require_access
def cmd_start(message: types.Message):
    chat_id = message.chat.id

    # ‚úÖ –ó–ë–ï–†–ï–ñ–ï–ù–ù–Ø –î–ê–ù–ò–• –ö–û–†–ò–°–¢–£–í–ê–ß–ê (id, first_name, last_name, username)
    save_user_if_new(message.from_user)

    st = user_states.setdefault(chat_id, UserState())

    if getattr(st, "current_pairs", None) is None:
        st.current_pairs = GLOBAL_CURRENT_PAIRS
    if getattr(st, "plus35_pairs", None) is None:
        st.plus35_pairs = GLOBAL_PLUS35_PAIRS

    has_current = bool(st.current_pairs)

    # üß≠ –°–∫–∏–¥–∞—î–º–æ —Ä–æ–±–æ—á—ñ —Ñ–∞–∑–∏/–±—É—Ñ–µ—Ä–∏
    st.alloc_mode = None
    st.main_agg_df = None
    st.offers = []
    st.current_offer_index = 0

    if has_current:
        # ‚úÖ current —É–∂–µ –≤—ñ–¥–æ–º–∏–π ‚Äî –æ–¥—Ä–∞–∑—É –ø—Ä–æ—Å–∏–º–æ –≥–æ–ª–æ–≤–Ω—É —Ç–∞–±–ª–∏—Ü—é
        st.phase = "WAIT_MAIN"
        bot.reply_to(
            message,
            (
                "–ü—Ä–∏–≤—ñ—Ç! üëã\n\n"
                "–ú–æ–∂–Ω–∞ –æ–¥—Ä–∞–∑—É –Ω–∞–¥—Å–∏–ª–∞—Ç–∏ –≥–æ–ª–æ–≤–Ω—É —Ç–∞–±–ª–∏—Ü—é (CSV) ‚Äî –∞—Ä–∫—É—à BUDG –∑ –∫–æ–ª–æ–Ω–∫–∞–º–∏: –ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É, –ì–ï–û, –ó–∞–≥–∞–ª—å–Ω—ñ –≤–∏—Ç—Ä–∞—Ç–∏."
            ),
            parse_mode="HTML",
        )
    else:
        # ‚ùó current —â–µ –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏–π ‚Äî –ø—Ä–æ—Å–∏–º–æ –≤–ø–µ—Ä—à–µ
        st.phase = "WAIT_CURRENT"
        bot.reply_to(
            message,
            (
                "–ü—Ä–∏–≤—ñ—Ç! üëã\n\n"
                "–°–ø–æ—á–∞—Ç–∫—É –Ω–∞–¥—ñ—à–ª—ñ—Ç—å —Ñ–∞–π–ª <b>current.xlsx</b>/<b>.csv</b> –∑ –∫–æ–ª–æ–Ω–∫–∞–º–∏ "
                "<i>–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É</i> —ñ <i>–ì–ï–û</i> ‚Äî —è –∑–±–µ—Ä–µ–∂—É –ø–∞—Ä–∏ —Ç–∞ –¥–æ–¥–∞–≤–∞—Ç–∏–º—É –∫–æ–ª–æ–Ω–∫—É <b>Current</b> (+/‚àí). "
                "–¶–µ –æ–¥–Ω–æ—Ä–∞–∑–æ–≤–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è: –Ω–∞–¥–∞–ª—ñ –ø–æ–≤—Ç–æ—Ä–Ω–æ –Ω–∞–¥—Å–∏–ª–∞—Ç–∏ —Ñ–∞–π–ª –Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω–æ.\n\n"
                "–ü—ñ—Å–ª—è —Ü—å–æ–≥–æ ‚Äî –Ω–∞–¥—ñ—à–ª—ñ—Ç—å –≥–æ–ª–æ–≤–Ω—É —Ç–∞–±–ª–∏—Ü—é BUDG."
            ),
            parse_mode="HTML",
        )


@bot.message_handler(content_types=["document"])
@require_access
def on_document(message: types.Message):
    import pandas as pd

    chat_id = message.chat.id
    state = user_states.setdefault(chat_id, UserState())

    try:
        # === 1. –û–±—Ä–æ–±–∫–∞ —Ñ–∞–π–ª—ñ–≤ current.xlsx / plus35.xlsx ===
        if state.phase in ("WAIT_CURRENT", "WAIT_PLUS35"):
            filename = message.document.file_name or "file"
            file_info = bot.get_file(message.document.file_id)
            file_bytes = bot.download_file(file_info.file_path)

            # –∑—á–∏—Ç—É–≤–∞–Ω–Ω—è XLSX / CSV
            import io, pandas as pd
            if filename.lower().endswith((".xlsx", ".xls")):
                dfp = pd.read_excel(io.BytesIO(file_bytes))
            elif filename.lower().endswith(".csv"):
                dfp = pd.read_csv(io.BytesIO(file_bytes))
            else:
                bot.reply_to(message, "‚ö†Ô∏è –ü—ñ–¥—Ç—Ä–∏–º—É—é—Ç—å—Å—è –ª–∏—à–µ .xlsx/.xls/.csv —Ñ–∞–π–ª–∏")
                return

            # —É–Ω—ñ—Ñ—ñ–∫–æ–≤–∞–Ω–µ –≤–∏—Ç—è–≥–Ω–µ–Ω–Ω—è –ø–∞—Ä
            lower = {str(c).strip().lower(): c for c in dfp.columns}
            offer_col = lower.get("–Ω–∞–∑–≤–∞ –æ—Ñ—Ñ–µ—Ä—É") or lower.get("offer") or lower.get("–æ—Ñ—Ñ–µ—Ä")
            geo_col = lower.get("–≥–µ–æ") or lower.get("geo") or lower.get("–∫—Ä–∞—ó–Ω–∞")

            if not (offer_col and geo_col):
                bot.reply_to(message, "‚ùå –£ —Ñ–∞–π–ª—ñ –º–∞—é—Ç—å –±—É—Ç–∏ –∫–æ–ª–æ–Ω–∫–∏ '–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É' —ñ '–ì–ï–û'")
                return

            def _norm(s: str) -> str:
                s = str(s or "").strip().lower()
                s = s.replace("‚Äô", "'").replace("`", "'").replace("‚Äì", "-").replace("‚Äî", "-")
                s = re.sub(r"\s+", " ", s)
                return s

            pairs = {
                (_norm(r[offer_col]), _norm(r[geo_col]))
                for _, r in dfp.dropna(subset=[offer_col, geo_col]).iterrows()
            }

            # –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ state
            if state.phase == "WAIT_CURRENT":
                state.current_pairs = pairs
                # update globals + persist
                globals()["GLOBAL_CURRENT_PAIRS"] = pairs
                save_pairs()

                bot.reply_to(
                    message,
                    f"‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ {len(pairs)} –ø–æ—Ç–æ—á–Ω–∏—Ö –ø–∞—Ä. –ú–æ–∂–Ω–∞ –Ω–∞–¥—Å–∏–ª–∞—Ç–∏ –≥–æ–ª–æ–≤–Ω—É —Ç–∞–±–ª–∏—Ü—é (BUDG).",
                    parse_mode="HTML",
                )
                state.phase = "WAIT_MAIN"
                return

            elif state.phase == "WAIT_PLUS35":
                state.plus35_pairs = pairs
                # update globals + persist
                globals()["GLOBAL_PLUS35_PAIRS"] = pairs
                save_pairs()

                bot.reply_to(
                    message,
                    f"‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ {len(pairs)} –ø–∞—Ä –¥–ª—è 35% –Ω–∞—Ü—ñ–Ω–∫–∏. –ú–æ–∂–Ω–∞ –ø—Ä–æ–¥–æ–≤–∂—É–≤–∞—Ç–∏.",
                    parse_mode="HTML",
                )
                # phase stays as-is
                return

            return

        # === 2. –Ü–Ω—à—ñ —Ñ–∞–π–ª–∏ (BUDG, –¥–æ–¥–∞—Ç–∫–æ–≤—ñ, Result) ===
        file_info = bot.get_file(message.document.file_id)
        file_bytes = bot.download_file(file_info.file_path)
        filename = message.document.file_name or "uploaded"

    except Exception as e:
        bot.reply_to(message, f"‚ùå –ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è —Ñ–∞–π–ª—É: <code>{e}</code>", parse_mode="HTML")
        return

    try:
        # --- –ì–û–õ–û–í–ù–ê –¢–ê–ë–õ–ò–¶–Ø ---
        if state.phase == "WAIT_MAIN":
            df = load_main_budg_table(file_bytes, filename=filename)
            bot.reply_to(message, "‚úÖ –ì–æ–ª–æ–≤–Ω–∞ —Ç–∞–±–ª–∏—Ü—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞! –¢–µ–ø–µ—Ä –Ω–∞–¥—ñ—à–ª—ñ—Ç—å –¥–æ–¥–∞—Ç–∫–æ–≤—ñ —Ç–∞–±–ª–∏—Ü—ñ.")
            handle_main_table(message, state, df)
            return

        # --- –î–û–î–ê–¢–ö–û–í–Ü –¢–ê–ë–õ–ò–¶–Ü ---
        elif state.phase == "WAIT_ADDITIONAL":
            df = read_additional_table(file_bytes, filename)
            handle_additional_table(message, state, df)
            return

        # --- –†–ï–ó–£–õ–¨–¢–ê–¢ (Result.xlsx) –¥–ª—è –∞–ª–æ–∫–∞—Ü—ñ—ó ---
        elif state.phase == "WAIT_ALLOC_RESULT":
            import io
            bio = io.BytesIO(file_bytes)
            try:
                df_res = pd.read_excel(bio, sheet_name="Result", engine="openpyxl")
            except Exception:
                bio.seek(0)
                df_res = pd.read_excel(bio, engine="openpyxl")

            # –æ—á–∏—â–µ–Ω–Ω—è –Ω–∞–∑–≤ –∫–æ–ª–æ–Ω–æ–∫
            df_res.columns = [str(c).replace("\xa0", " ").replace("\u00A0", " ").strip() for c in df_res.columns]

            # –±–∞–∑–æ–≤—ñ —á–∏—Å–ª–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏
            for num_col in ["FTD qty", "Total spend", "Total Dep Amount"]:
                if num_col in df_res.columns:
                    df_res[num_col] = pd.to_numeric(df_res[num_col], errors="coerce").fillna(0)

            state.alloc_df = df_res

            if state.alloc_mode == "alternative_leftover":
                # run allocation till L-adjust (no Pass#2), and get leftover
                out_df, leftover = allocate_total_spend_alternative(
                    df_res,
                    col_total_spend="Total spend",
                    col_ftd_qty="FTD qty",
                    col_cpa_target="CPA Target",
                    col_my_deposit="My deposit amount",
                    col_total_dep_amount="Total Dep Amount",
                    col_geo="–ì–ï–û",
                    col_offer="–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É",
                    plus35_pairs=getattr(state, "plus35_pairs", None),
                    skip_pass2=True,
                    return_leftover=True,
                    excel_path="allocation_pass1_only.xlsx",
                    sheet_name="Result",
                )

                # send the file (optional)
                try:
                    with open("allocation_pass1_only.xlsx", "rb") as f:
                        bot.send_document(
                            message.chat.id,
                            f,
                            visible_file_name="allocation_pass1_only.xlsx")
                except Exception:
                    pass

                # send leftover summary
                bot.send_message(
                    message.chat.id,
                    f"–ó–∞–ª–∏—à–æ–∫ –±—é–¥–∂–µ—Ç—É –ø—ñ—Å–ª—è —Ä–æ–∑–ø–æ–¥—ñ–ª—É: $<b>{leftover:,.2f}</b>",
                    parse_mode="HTML"
                )

                state.phase = "WAIT_MAIN"
                return

            # —è–∫—â–æ —Ä–µ–∂–∏–º "alternative"
            if state.alloc_mode == "alternative":
                _run_alternative_and_send(chat_id, state)
                return

            # —ñ–Ω—à—ñ —Ä–µ–∂–∏–º–∏ (openai –∞–±–æ –∑–≤–∏—á–∞–π–Ω–∞ –∞–ª–æ–∫–∞—Ü—ñ—è)
            state.phase = "WAIT_ALLOC_BUDGET"
            bot.reply_to(message, "‚úÖ –§–∞–π–ª Result –ø—Ä–∏–π–Ω—è—Ç–æ. –í–≤–µ–¥—ñ—Ç—å, –±—É–¥—å –ª–∞—Å–∫–∞, –±—é–¥–∂–µ—Ç (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥: 200).")
            return

        # --- –û–ë‚Äô–Ñ–î–ù–ê–ù–ù–Ø UA/RU –ö–†–ê–á–ù –î–õ–Ø /unite_geo ---
        elif state.phase == "WAIT_UNITE_TABLE":
            import io
            bio = io.BytesIO(file_bytes)
            fname = (filename or "").lower()
            try:
                if fname.endswith((".xlsx", ".xls", ".xlsm")):
                    df_in = pd.read_excel(bio)
                elif fname.endswith(".csv"):
                    bio.seek(0)
                    df_in = pd.read_csv(bio)
                else:
                    bot.reply_to(message, "‚ö†Ô∏è –ù–∞–¥—ñ—à–ª—ñ—Ç—å —Ñ–∞–π–ª —É —Ñ–æ—Ä–º–∞—Ç—ñ .xlsx/.xls/.xlsm/.csv")
                    return
            except Exception as e:
                bot.reply_to(message, f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç–∏ —Ñ–∞–π–ª: <code>{e}</code>", parse_mode="HTML")
                return

            # –í–∏—è–≤–∏—Ç–∏ –Ω–∞–∑–≤–∏ –∫–æ–ª–æ–Ω–æ–∫
            country_col = next((c for c in ("–ì–ï–û", "–ì–µ–æ", "GEO") if c in df_in.columns), None)
            if not country_col:
                bot.reply_to(message, "‚ùå –£ —Ñ–∞–π–ª—ñ –Ω–µ–º–∞—î –∫–æ–ª–æ–Ω–∫–∏ –∫—Ä–∞—ó–Ω–∏ ('–ì–ï–û' / '–ì–µ–æ' / 'GEO').")
                return

            spend_col = next((c for c in ("Total spend", "Total Spend", "–ó–∞–≥–∞–ª—å–Ω—ñ –≤–∏—Ç—Ä–∞—Ç–∏") if c in df_in.columns),
                             None)
            if not spend_col:
                bot.reply_to(
                    message,
                    "‚ùå –£ —Ñ–∞–π–ª—ñ –Ω–µ–º–∞—î –∫–æ–ª–æ–Ω–∫–∏ –≤–∏—Ç—Ä–∞—Ç ('Total spend' / 'Total Spend' / '–ó–∞–≥–∞–ª—å–Ω—ñ –≤–∏—Ç—Ä–∞—Ç–∏')."
                )
                return

            offer_col = "–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É"
            if offer_col not in df_in.columns:
                bot.reply_to(message, "‚ùå –£ —Ñ–∞–π–ª—ñ –Ω–µ–º–∞—î –∫–æ–ª–æ–Ω–∫–∏ '–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É'.")
                return

            # 1) –û–±'—î–¥–Ω–∞—Ç–∏ —Ç—ñ–ª—å–∫–∏ –≤ –º–µ–∂–∞—Ö (–û—Ñ—Ñ–µ—Ä + GEO UA/RU)
            try:
                merged = unite_ua_ru_rows(
                    df_in,
                    country_col=country_col,
                    total_spend_col=spend_col,
                    offer_col=offer_col,  # üëà –≤–∞–∂–ª–∏–≤–æ!
                )
            except Exception as e:
                bot.reply_to(message, f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –æ–±‚Äô—î–¥–Ω–∞–Ω–Ω—è: <code>{e}</code>", parse_mode="HTML")
                return

            # Fix capitalization + special case for Congo
            if "–ì–ï–û" in merged.columns:
                merged["–ì–ï–û"] = merged["–ì–ï–û"].apply(lambda x: str(x).capitalize() if isinstance(x, str) else x)
                merged["–ì–ï–û"] = merged["–ì–ï–û"].replace(r"(?i)^—Ä–µ—Å–ø—É–±–ª—ñ–∫–∞\s+–∫–æ–Ω–≥–æ$", "–ö–æ–Ω–≥–æ", regex=True)

            # 2) –ü–æ–±—É–¥—É–≤–∞—Ç–∏ –≤–∏—Ö—ñ–¥ —è–∫ –ø–æ–≤–Ω–∏–π Result —ñ –ü–û–í–¢–û–†–ù–û –∑–∞—Å—Ç–æ—Å—É–≤–∞—Ç–∏ —Ñ–æ—Ä–º—É–ª–∏
            #    (–±–µ—Ä–µ–º–æ –≤—Å—ñ –ø–æ—Ç—Ä—ñ–±–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏; —è–∫—â–æ —á–æ–≥–æ—Å—å –Ω–µ–º–∞—î ‚Äî –¥–æ–¥–∞—î–º–æ –ø–æ—Ä–æ–∂–Ω—ñ)
            result_cols = [
                "Subid", "Offer ID", "–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É", "–ì–ï–û",
                "FTD qty", "Total spend", "Total+%", "CPA", "CPA Target", "–°P/–ß",
                "Total Dep Amount", "My deposit amount",
                "C. profit Target 40%", "C. profit Target 50%",
                "CAP", "–û—Å—Ç–∞—Ç–æ–∫ CAP", "Current"
            ]

            # –ü—Ä–∏–≤–µ—Å—Ç–∏ —ñ–º–µ–Ω–∞ –≤ merged: –ø–µ—Ä–µ–π–º–µ–Ω—É–≤–∞—Ç–∏ spend_col -> "Total spend" —ñ GEO -> "–ì–ï–û"
            merged = merged.copy()
            if spend_col != "Total spend" and spend_col in merged.columns:
                merged.rename(columns={spend_col: "Total spend"}, inplace=True)
            if country_col != "–ì–ï–û" and country_col in merged.columns:
                merged.rename(columns={country_col: "–ì–ï–û"}, inplace=True)

            # –ó–∞–±–µ–∑–ø–µ—á–∏—Ç–∏ –≤—Å—ñ –∫–æ–ª–æ–Ω–∫–∏
            for c in result_cols:
                if c not in merged.columns:
                    merged[c] = None

            # –ü—Ä–∏–≤–µ—Å—Ç–∏ –ø–æ—Ä—è–¥–æ–∫
            merged = merged[result_cols].copy()

            # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ Current (+/-) –ø–æ –∑–±–µ—Ä–µ–∂–µ–Ω–∏–º –ø–∞—Ä–∞–º
            st = user_states.get(message.chat.id)
            pairs = (getattr(st, "current_pairs", None) or globals().get("GLOBAL_CURRENT_PAIRS"))

            def _n(s: str) -> str:
                s = str(s or "").strip().lower()
                s = s.replace("‚Äô", "'").replace("`", "'").replace("‚Äì", "-").replace("‚Äî", "-")
                return " ".join(s.split())

            def _pair(r):
                return (_n(r.get("–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É", "")), _n(r.get("–ì–ï–û", "")))

            merged["Current"] = merged.apply(lambda r: "+" if (pairs and _pair(r) in pairs) else "-", axis=1)

            # 3) –ó–∞–ø–∏—Å–∞—Ç–∏ Excel + —Ñ–æ—Ä–º—É–ª–∏
            out = io.BytesIO()
            with pd.ExcelWriter(out, engine="openpyxl") as writer:
                merged.to_excel(writer, index=False, sheet_name="Merged")
                ws = writer.book["Merged"]

                from openpyxl.styles import PatternFill, Alignment, Font
                from openpyxl.formatting.rule import FormulaRule

                header_row = 1
                first_row = 2
                last_row = ws.max_row

                # –ú–Ω–æ–∂–Ω–∏–∫ –∑–∞ plus35_pairs
                p35 = (getattr(st, "plus35_pairs", None) or globals().get("GLOBAL_PLUS35_PAIRS"))

                # –§–æ—Ä–º—É–ª–∏
                for r in range(first_row, last_row + 1):
                    offer_val = ws[f"C{r}"].value  # –ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É
                    geo_val = ws[f"D{r}"].value  # –ì–ï–û

                    mul = 1.35 if (p35 and (_n(offer_val), _n(geo_val)) in p35) else 1.30

                    ws[f"G{r}"].value = f"=F{r}*{mul}"  # Total+%
                    ws[f"H{r}"].value = f"=IFERROR(G{r}/E{r},\"\")"  # CPA
                    ws[f"I{r}"].value = cpa_target_for_geo(ws[f"D{r}"].value)  # CPA Target
                    ws[f"J{r}"].value = f"=IFERROR(K{r}/E{r},\"\")"  # –°P/–ß
                    ws[f"L{r}"].value = f"=IFERROR(K{r}/G{r}*100,0)"  # My deposit amount
                    ws[f"M{r}"].value = f"=G{r}*0.4"  # Profit 40%
                    ws[f"N{r}"].value = f"=G{r}*0.5"  # Profit 50%

                # –§–æ—Ä–º–∞—Ç–∏ —á–∏—Å–µ–ª
                for r in range(first_row, last_row + 1):
                    ws[f"E{r}"].number_format = "0"
                for c in ("F", "G", "H", "J", "K", "L", "M", "N"):
                    for r in range(first_row, last_row + 1):
                        ws[f"{c}{r}"].number_format = "0.00"

                # –®–∞–ø–∫–∞
                for col in range(1, 17):
                    ws.cell(row=1, column=col).font = Font(bold=True)
                    ws.cell(row=1, column=col).alignment = Alignment(horizontal="center")

                widths = {
                    "A": 10, "B": 12, "C": 22, "D": 16, "E": 10, "F": 14, "G": 12, "H": 10, "I": 12,
                    "J": 10, "K": 16, "L": 18, "M": 18, "N": 18, "O": 12, "P": 16
                }
                for col, w in widths.items():
                    ws.column_dimensions[col].width = w

                # (–û–ø—Ü—ñ–π–Ω–æ) —Ç–≤–æ—ó –∂ —É–º–æ–≤–Ω—ñ —Ñ–æ—Ä–º–∞—Ç–∏
                data_range = f"A{first_row}:P{last_row}"
                grey = PatternFill("solid", fgColor="BFBFBF")
                green = PatternFill("solid", fgColor="C6EFCE")
                yellow = PatternFill("solid", fgColor="FFEB9C")
                red = PatternFill("solid", fgColor="FFC7CE")

                ws.conditional_formatting.add(data_range, FormulaRule(formula=["$E2=0"], fill=grey, stopIfTrue=True))
                ws.conditional_formatting.add(
                    data_range,
                    FormulaRule(formula=["AND($E2>0,INT($H2)<=INT($I2),$L2>39)"], fill=green, stopIfTrue=True)
                )
                ws.conditional_formatting.add(
                    data_range,
                    FormulaRule(formula=["AND($E2>0,OR(INT($H2)<=INT($I2),AND($L2>39,$H2<$I2*1.31)))"], fill=yellow,
                                stopIfTrue=True)
                )
                ws.conditional_formatting.add(
                    data_range, FormulaRule(
                        formula=["OR(AND($E2>0,$H2>$I2*1.3,$L2>39),AND($E2>0,INT($H2)>INT($I2),$L2<39))"],
                        fill=red, stopIfTrue=True
                    )
                )

            out.seek(0)
            bot.send_document(
                chat_id,
                out,
                visible_file_name="merged_countries.xlsx",
                caption="‚úÖ –ì–æ—Ç–æ–≤–æ! UA/RU –∫—Ä–∞—ó–Ω–∏ –æ–±‚Äô—î–¥–Ω–∞–Ω–æ –≤ –º–µ–∂–∞—Ö –æ–¥–Ω–æ–≥–æ –æ—Ñ—Ñ–µ—Ä–∞. –§–æ—Ä–º—É–ª–∏ –∑–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–æ.",
            )

            state.phase = "WAIT_MAIN"
            return

        else:
            bot.reply_to(message, "‚ö†Ô∏è –ù–µ—Å–ø–æ–¥—ñ–≤–∞–Ω–∞ —Ñ–∞–∑–∞. –ü–æ—á–Ω—ñ—Ç—å —Å–ø–æ—á–∞—Ç–∫—É –∑ /start.")
            return

    except ValueError as ve:
        bot.reply_to(message, f"‚ùå –ü–æ–º–∏–ª–∫–∞ —É —Ñ–∞–π–ª—ñ <b>{filename}</b>:\n<code>{ve}</code>", parse_mode="HTML")
    except Exception as e:
        bot.reply_to(message, f"‚ö†Ô∏è –ù–µ–ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∞ –ø–æ–º–∏–ª–∫–∞: <code>{e}</code>", parse_mode="HTML")


@bot.message_handler(commands=["allocate"])
@require_access
def cmd_allocate(message: types.Message):
    chat_id = message.chat.id
    state = user_states.setdefault(chat_id, UserState())

    # —Å–∫–∏–Ω–µ–º–æ –ø—Ä–æ–º—ñ–∂–Ω–∏–π —Å—Ç–∞–Ω –∞–ª–æ–∫–∞—Ü—ñ—ó
    state.alloc_df = None
    state.alloc_budget = None
    state.alloc_mode = None
    state.phase = "WAIT_ALLOC_MODE"

    kb = types.InlineKeyboardMarkup(row_width=2)
    # kb.add(
    #     types.InlineKeyboardButton("üîπ –ü—Ä–æ—Ö—ñ–¥ –ü–æ –û–¥–Ω–æ–º—É –∑ KPI + –ó–∞–ª–∏—à–æ–∫", callback_data="alloc_mode:alternative"),
    # )
    kb.add(
        types.InlineKeyboardButton("üîπ –ü—Ä–æ—Ö—ñ–¥ –ü–æ –û–¥–Ω–æ–º—É –∑ KPI", callback_data="alloc_mode:alternative_leftover"),
    )

    bot.reply_to(
        message,
        "–û–±–µ—Ä—ñ—Ç—å —Ä–µ–∂–∏–º –∞–ª–æ–∫–∞—Ü—ñ—ó:",
        reply_markup=kb
    )


@bot.callback_query_handler(func=lambda c: c.data and c.data.startswith("alloc_mode:"))
@require_access_cb
def on_alloc_mode(call: types.CallbackQuery):
    chat_id = call.message.chat.id
    state = user_states.setdefault(chat_id, UserState())
    mode = call.data.split(":", 1)[1]

    if mode not in {"optimal", "alternative", "alternative_leftover", "openai"}:
        bot.answer_callback_query(call.id, "–ù–µ–≤—ñ–¥–æ–º–∏–π —Ä–µ–∂–∏–º.")
        return

    state.alloc_mode = mode
    # –ü—ñ—Å–ª—è –≤–∏–±–æ—Ä—É —Ä–µ–∂–∏–º—É –ø—Ä–æ—Å–∏–º–æ result.xlsx (–¥–ª—è –±—É–¥—å-—è–∫–æ–≥–æ —Ä–µ–∂–∏–º—É)
    state.phase = "WAIT_ALLOC_RESULT"
    bot.answer_callback_query(call.id, "–†–µ–∂–∏–º –æ–±—Ä–∞–Ω–æ.")
    bot.send_message(
        chat_id,
        (
            "–ù–∞–¥—ñ—à–ª—ñ—Ç—å —Ñ–∞–π–ª <b>result.xlsx</b> (—Ç–æ–π, —â–æ –±–æ—Ç –∑–≥–µ–Ω–µ—Ä—É–≤–∞–≤ —Ä–∞–Ω—ñ—à–µ).\n\n"
            "–ü—ñ—Å–ª—è –ø–µ—Ä–µ—Ä–æ–∑–ø–æ–¥—ñ–ª—É:\n"
            "- –°–ø–µ–Ω–¥ –±—É–¥–µ –ø–µ—Ä–µ—Ä–æ–∑–ø–æ–¥—ñ–ª–µ–Ω–∏–π –ø—ñ–¥ –ø—Ä–æ—Ö—ñ–¥ –ø–æ 1 –∑ –ö–†–Ü.\n"
            "- –ó–∞–±–µ—Ä–µ—Ç—å—Å—è —Å–ø–µ–Ω–¥ –∑ –æ—Ñ—Ñ–µ—Ä—ñ–≤ –Ω–∞ —è–∫–∏—Ö –≤—ñ–¥—Å—Ç—É–ø–Ω—ñ –¥–µ–ø–æ–∑–∏—Ç–∏ —Ç–∞ –Ω–µ–º–∞—î –∞–∫—Ç—É–∞–ª—å–Ω–∏—Ö –∫–∞–ø –Ω–∞ –ø–æ—Ç–æ—á–Ω–∏–π –º—ñ—Å—è—Ü—å\n"
            "- –ë–æ—Ç –≤–∏–≤–µ–¥–µ –≤–∞–º –∑–∞–ª–∏—à–æ–∫ —Å–ø–µ–Ω–¥–∞, –ø—ñ—Å–ª—è –ø–µ—Ä–µ—Ä–æ–∑–ø–æ–¥—ñ–ª—É –¥–æ –æ–¥–Ω–æ–≥–æ –∑ –ö–†–Ü, —è–∫–∏–π –±—É–¥–µ –ø–æ—Ç—Ä—ñ–±–Ω–æ —Ä–æ–∑–∫–∏–Ω—É—Ç–∏ –≤—Ä—É—á–Ω—É."
        ),
        parse_mode="HTML"
    )


@bot.message_handler(content_types=["text"], func=lambda m: not (m.text or "").startswith("/"))
@require_access
def on_text(message: types.Message):
    chat_id = message.chat.id
    state = user_states.setdefault(chat_id, UserState())

    # –ø–µ—Ä–µ—Ö–æ–ø–ª—é—î–º–æ —Ç—ñ–ª—å–∫–∏ —É —Ñ–∞–∑—ñ –∞–ª–æ–∫–∞—Ü—ñ—ó
    if state.phase != "WAIT_ALLOC_BUDGET":
        return

    # ===== –õ–æ–∫–∞–ª—å–Ω—ñ —Ä–µ–∂–∏–º–∏: –Ω–∏–∂—á–µ –≤—Å–µ —è–∫ –±—É–ª–æ (–ø–æ—Ç—Ä—ñ–±–µ–Ω –±—é–¥–∂–µ—Ç) =====
    # Parse budget
    txt = (message.text or "").strip().replace(",", ".")
    try:
        budget = float(txt)
        if budget < 0:
            raise ValueError("negative")
    except Exception:
        bot.reply_to(message, "–í–≤–µ–¥–∏, –±—É–¥—å –ª–∞—Å–∫–∞, –∫–æ—Ä–µ–∫—Ç–Ω–µ –¥–æ–¥–∞—Ç–Ω—î —á–∏—Å–ª–æ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥: 200).")
        return

    if state.alloc_df is None or len(state.alloc_df) == 0:
        bot.reply_to(message, "–ù–µ–º–∞—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ—ó —Ç–∞–±–ª–∏—Ü—ñ Result. –í–∏–∫–æ—Ä–∏—Å—Ç–∞–π /allocate —â–µ —Ä–∞–∑.")
        state.phase = "WAIT_MAIN"
        return

    # –õ–æ–∫–∞–ª—å–Ω–∞ –∞–ª–æ–∫–∞—Ü—ñ—è
    alloc_df, summary, alloc_vec = compute_optimal_allocation(state.alloc_df, budget)

    # –§–æ—Ä–º—É—î–º–æ —Ñ–∞–π–ª —ñ–∑ –Ω–æ–≤–∏–º–∏ –≤–∏—Ç—Ä–∞—Ç–∞–º–∏
    bio = io.BytesIO()
    write_result_like_excel_with_new_spend(bio, state.alloc_df, new_total_spend=alloc_vec)

    bio.seek(0)
    bot.send_document(
        chat_id,
        bio,
        visible_file_name="allocation.xlsx",
        caption=summary  # –∫–æ—Ä–æ—Ç–∫–∏–π –ø—ñ–¥—Å—É–º–æ–∫
    )

    # –î–µ—Ç–∞–ª—å–Ω–µ –ø–æ—è—Å–Ω–µ–Ω–Ω—è
    explanation = build_allocation_explanation(state.alloc_df, alloc_vec, budget, max_lines=20)
    bot.send_message(chat_id, explanation)

    state.phase = "WAIT_MAIN"


@bot.callback_query_handler(func=lambda c: c.data == "skip_offer")
@require_access_cb
def on_skip_offer(call: types.CallbackQuery):
    chat_id = call.message.chat.id
    state = user_states.setdefault(chat_id, UserState())

    # –Ø–∫—â–æ –≤–∂–µ –ø–æ–∑–∞ –º–µ–∂–∞–º–∏ ‚Äî –ø—Ä–æ—Å—Ç–æ —ñ–≥–Ω–æ—Ä—É—î–º–æ
    if state.current_offer_index >= len(state.offers):
        bot.answer_callback_query(call.id, "–ù–µ–º–∞—î –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –æ—Ñ–µ—Ä—É.")
        return

    offer = state.offers[state.current_offer_index]

    # –í–ê–ñ–õ–ò–í–û: –ø—Ä–∏ –ø—Ä–æ–ø—É—Å–∫—É ‚Äî –ù–ï –¥–æ–¥–∞—î–º–æ —Ü–µ–π –æ—Ñ–µ—Ä —É —Ä–µ–∑—É–ª—å—Ç–∞—Ç,
    # —Ç–æ–∂ –ø—Ä–æ—Å—Ç–æ –ø—Ä–∏–±–∏—Ä–∞—î–º–æ –π–æ–≥–æ –∑ –ø—Ä–æ–º—ñ–∂–Ω–∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä (—è–∫—â–æ —Ç–∏ –∑–±–µ—Ä—ñ–≥–∞—î—à –∞–≥—Ä–µ–≥–∞—Ç–∏)
    if hasattr(state, "main_agg_df") and state.main_agg_df is not None:
        # –ø–æ–≤–Ω—ñ—Å—Ç—é –∑–∞–±–∏—Ä–∞—î–º–æ —Ä—è–¥–∫–∏ —Ü—å–æ–≥–æ –æ—Ñ–µ—Ä—É, —â–æ–± –Ω–µ –ø–æ—Ç—Ä–∞–ø–∏–ª–∏ —É —Ñ—ñ–Ω–∞–ª—å–Ω–∏–π Excel
        state.main_agg_df = state.main_agg_df[state.main_agg_df["–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É"] != offer]

    # –ø–µ—Ä–µ—Ö—ñ–¥ –¥–æ –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ –æ—Ñ–µ—Ä—É
    state.current_offer_index += 1
    bot.answer_callback_query(call.id, "–û—Ñ–µ—Ä –ø—Ä–æ–ø—É—â–µ–Ω–æ.")

    # —è–∫—â–æ —â–µ —î –æ—Ñ–µ—Ä–∏ ‚Äî –ø–æ–ø—Ä–æ—Å–∏–º–æ –Ω–∞—Å—Ç—É–ø–Ω—É –¥–æ–¥–∞—Ç–∫–æ–≤—É —Ç–∞–±–ª–∏—Ü—é
    if state.current_offer_index < len(state.offers):
        ask_additional_table_with_skip(call.message, state)
    else:
        # —è–∫—â–æ –æ—Ñ–µ—Ä—ñ–≤ –±—ñ–ª—å—à–µ –Ω–µ–º–∞—î ‚Äî –≥–µ–Ω–µ—Ä—É—î–º–æ —Ñ—ñ–Ω–∞–ª—å–Ω–∏–π —Ñ–∞–π–ª
        try:
            final_df = build_final_output(state)
            send_final_table(call.message, final_df)
        except Exception as e:
            bot.send_message(chat_id, f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å —Ñ–æ—Ä–º—É–≤–∞–Ω–Ω—è —Ñ–∞–π–ª—É: <code>{e}</code>")


@bot.message_handler(commands=["current"])
@require_access
def cmd_current(message: types.Message):
    st = user_states.setdefault(message.chat.id, UserState())
    st.phase = "WAIT_CURRENT"
    bot.reply_to(
        message,
        "üì• –ù–∞–¥—ñ—à–ª—ñ—Ç—å —Ñ–∞–π–ª <b>current.xlsx</b> –∞–±–æ <b>current.csv</b> "
        "–∑ –∫–æ–ª–æ–Ω–∫–∞–º–∏ '–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É' —Ç–∞ '–ì–ï–û'. –¶–µ–π —Ñ–∞–π–ª –±—É–¥–µ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —ñ –Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω–æ –±—É–¥–µ –Ω–∞–¥—Å–∏–ª–∞—Ç–∏ –π–æ–≥–æ —â–æ—Ä–∞–∑—É.",
        parse_mode="HTML",
    )


@bot.message_handler(commands=["plus35"])
@require_access
def cmd_plus35(message: types.Message):
    st = user_states.setdefault(message.chat.id, UserState())
    st.phase = "WAIT_PLUS35"
    bot.reply_to(message, "–ù–∞–¥—ñ—à–ª—ñ—Ç—å —Ñ–∞–π–ª <b>plus35.xlsx</b>/<b>.csv</b> –∑ –∫–æ–ª–æ–Ω–∫–∞–º–∏ '–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É' —ñ '–ì–ï–û' (–¥–ª—è 35%).",
                 parse_mode="HTML")


@bot.message_handler(commands=["whoami"])
def whoami(message: types.Message):
    bot.reply_to(message, f"–í–∞—à Telegram ID: <code>{message.from_user.id}</code>")


@bot.message_handler(commands=["unite_geo"])
@require_access
def cmd_unite_geo(message: types.Message):
    st = user_states.setdefault(message.chat.id, UserState())
    st.phase = "WAIT_UNITE_TABLE"
    bot.reply_to(
        message,
        "üìÑ –ù–∞–¥—ñ—à–ª—ñ—Ç—å Excel/CSV –∑ –∫–æ–ª–æ–Ω–∫–∞–º–∏ '–ì–ï–û' —ñ 'Total spend' (–∞–±–æ '–ó–∞–≥–∞–ª—å–Ω—ñ –≤–∏—Ç—Ä–∞—Ç–∏'). "
        "–Ø –æ–±‚Äô—î–¥–Ω–∞—é UA/RU –∫—Ä–∞—ó–Ω–∏ –≤ –æ–¥–∏–Ω —Ä—è–¥–æ–∫ –∑ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –Ω–∞–∑–≤–æ—é —ñ –ø—ñ–¥—Å—É–º–∫–æ–º –≤–∏—Ç—Ä–∞—Ç.",
        parse_mode="HTML",
    )


# ===================== MAIN TABLE LOGIC =====================

def handle_main_table(message: types.Message, state: UserState, df: pd.DataFrame):
    # Clean & coerce
    work = df.copy()
    work["–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É"] = work["–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É"].astype(str).str.strip()
    work["–ì–ï–û"] = work["–ì–ï–û"].astype(str).str.strip()
    work["–ó–∞–≥–∞–ª—å–Ω—ñ –≤–∏—Ç—Ä–∞—Ç–∏"] = pd.to_numeric(work["–ó–∞–≥–∞–ª—å–Ω—ñ –≤–∏—Ç—Ä–∞—Ç–∏"], errors="coerce").fillna(0.0)

    # Drop empty/placeholder Offer IDs - handle string values properly
    work = work[
        work["–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É"].ne("") &
        work["–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É"].ne("nan") &
        work["–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É"].ne("None") &
        work["–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É"].notna()
        ]

    # Also filter out rows where –ì–ï–û is empty
    work = work[
        work["–ì–ï–û"].ne("") &
        work["–ì–ï–û"].ne("nan") &
        work["–ì–ï–û"].ne("None") &
        work["–ì–ï–û"].notna()
        ]

    if len(work) == 0:
        bot.reply_to(message, "–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª—ñ–¥–Ω–∏—Ö –∑–∞–ø–∏—Å—ñ–≤ —É BUDG —Ç–∞–±–ª–∏—Ü—ñ –ø—ñ—Å–ª—è –æ—á–∏—â–µ–Ω–Ω—è.")
        return

    # Aggregate by Offer ID + GEO
    agg = (
        work.groupby(["–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É", "–ì–ï–û"])["–ó–∞–≥–∞–ª—å–Ω—ñ –≤–∏—Ç—Ä–∞—Ç–∏"]
        .sum().reset_index()
    )

    state.main_agg_df = agg

    # Unique Offer IDs (from cleaned data)
    state.offers = sorted(agg["–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É"].unique().tolist())
    state.phase = "WAIT_ADDITIONAL"
    state.current_offer_index = 0
    ask_additional_table_with_skip(message, state)

    if not state.offers:
        bot.reply_to(message, "–ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∂–æ–¥–Ω–æ–≥–æ –≤–∞–ª—ñ–¥–Ω–æ–≥–æ Offer ID —É –∞—Ä–∫—É—à—ñ BUDG –ø—ñ—Å–ª—è –æ—á–∏—â–µ–Ω–Ω—è.")
        return


# ===================== ADDITIONAL TABLE LOGIC =====================

def handle_additional_table(message: types.Message, state: UserState, df: pd.DataFrame):
    # 1) Clean & normalize
    work = df.copy()
    work["–ö—Ä–∞—ó–Ω–∞"] = work["–ö—Ä–∞—ó–Ω–∞"].astype(str).str.strip()
    work["–°—É–º–∞ –¥–µ–ø–æ–∑–∏—Ç—ñ–≤"] = pd.to_numeric(work["–°—É–º–∞ –¥–µ–ø–æ–∑–∏—Ç—ñ–≤"], errors="coerce").fillna(0.0)

    # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –ø–æ—Ä–æ–∂–Ω—ñ/–Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω—ñ –∫—Ä–∞—ó–Ω–∏
    work = work[
        work["–ö—Ä–∞—ó–Ω–∞"].ne("") &
        work["–ö—Ä–∞—ó–Ω–∞"].ne("nan") &
        work["–ö—Ä–∞—ó–Ω–∞"].ne("None") &
        work["–ö—Ä–∞—ó–Ω–∞"].notna()
        ]

    # 2) –í–∏–∑–Ω–∞—á–∞—î–º–æ –ø–æ—Ç–æ—á–Ω–∏–π –æ—Ñ–µ—Ä
    try:
        current_offer = state.offers[state.current_offer_index]
    except IndexError:
        bot.reply_to(message, "–ü–æ–º–∏–ª–∫–∞: –Ω–µ–º–∞—î –∞–∫—Ç–∏–≤–Ω–æ–≥–æ Offer ID. –ù–∞–ø–∏—à–∏ /start –¥–ª—è –ø–æ—á–∞—Ç–∫—É.")
        return

    # 3) –Ø–∫—â–æ –ø—ñ—Å–ª—è –æ—á–∏—â–µ–Ω–Ω—è –Ω–µ–º–∞—î –∂–æ–¥–Ω–æ–≥–æ –≤–∞–ª—ñ–¥–Ω–æ–≥–æ —Ä—è–¥–∫–∞ ‚Äî –ø—Ä–æ—Å—Ç–∞–≤–ª—è—î–º–æ –Ω—É–ª—ñ
    if len(work) == 0:
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ ¬´–Ω—É–ª—å–æ–≤—ñ¬ª –¥–µ–ø–æ–∑–∏—Ç–∏ –¥–ª—è –ª–æ–≥—ñ–∫–∏ —Ñ—ñ–Ω–∞–ª—å–Ω–æ–≥–æ –º–µ—Ä–¥–∂—É
        # (–ø–æ—Ä–æ–∂–Ω—ñ–π —Å–ª–æ–≤–Ω–∏–∫ –æ–∑–Ω–∞—á–∞—î, —â–æ –ø–æ –∫—Ä–∞—ó–Ω–∞—Ö –Ω—ñ—á–æ–≥–æ –Ω–µ –¥–æ–¥–∞–≤–∞—Ç–∏;
        # –Ω–∏–∂—á–µ —â–µ –π –≥–∞—Ä–∞–Ω—Ç—É—î–º–æ –Ω—É–ª—ñ —É –ø—Ä–æ–º—ñ–∂–Ω—ñ–π —Ç–∞–±–ª–∏—Ü—ñ, —è–∫—â–æ –≤–æ–Ω–∞ –≤–∂–µ —î)
        state.offer_deposits[current_offer] = {}

        # –Ø–∫—â–æ –≤ –ø–∞–º‚Äô—è—Ç—ñ –≤–∂–µ —î –∞–≥—Ä–µ–≥–æ–≤–∞–Ω–∞ –≥–æ–ª–æ–≤–Ω–∞ —Ç–∞–±–ª–∏—Ü—è ‚Äî –≥–∞—Ä–∞–Ω—Ç—É—î–º–æ –Ω—É–ª—ñ –¥–ª—è –ø–æ—Ç–æ—á–Ω–æ–≥–æ –æ—Ñ–µ—Ä—É
        if hasattr(state, "main_agg_df") and state.main_agg_df is not None:
            mask = state.main_agg_df["–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É"] == current_offer
            # —Å—Ç–≤–æ—Ä–∏–º–æ –∫–æ–ª–æ–Ω–∫–∏, —è–∫—â–æ —ó—Ö —â–µ –Ω–µ–º–∞—î
            if "Total Dep Sum" not in state.main_agg_df.columns:
                state.main_agg_df["Total Dep Sum"] = 0.0
            if "Total Dep Amount" not in state.main_agg_df.columns:
                state.main_agg_df["Total Dep Amount"] = 0
            # –Ω—É–ª—ñ –¥–ª—è –≤—Å—ñ—Ö —Ä—è–¥–∫—ñ–≤ —Ü—å–æ–≥–æ –æ—Ñ–µ—Ä—É
            state.main_agg_df.loc[mask, "Total Dep Sum"] = 0.0
            state.main_agg_df.loc[mask, "Total Dep Amount"] = 0

        # –ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—É
        bot.reply_to(
            message,
            (
                f"‚ÑπÔ∏è –£ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ–π —Ç–∞–±–ª–∏—Ü—ñ –¥–ª—è <b>{current_offer}</b> –Ω–µ–º–∞—î –¥–∞–Ω–∏—Ö –ø—ñ—Å–ª—è –æ—á–∏—â–µ–Ω–Ω—è.\n"
                f"–î–ª—è —Ü—å–æ–≥–æ –æ—Ñ–µ—Ä—É –ø—Ä–æ—Å—Ç–∞–≤–ª–µ–Ω–æ <b>0</b> —É –∫–æ–ª–æ–Ω–∫–∞—Ö –¥–µ–ø–æ–∑–∏—Ç—ñ–≤."
            ),
        )

        # –ü–µ—Ä–µ—Ö—ñ–¥ –¥–æ –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ –æ—Ñ–µ—Ä—É / —Ñ—ñ–Ω–∞–ª
        state.current_offer_index += 1
        if state.current_offer_index >= len(state.offers):
            final_df = build_final_output(state)
            send_final_table(message, final_df)
            user_states[message.chat.id] = UserState()  # reset
            return

        next_offer = state.offers[state.current_offer_index]
        bot.reply_to(
            message,
            (
                f"–ù–∞–¥—ñ—à–ª—ñ—Ç—å –¥–æ–¥–∞—Ç–∫–æ–≤—É —Ç–∞–±–ª–∏—Ü—é –¥–ª—è <b>{next_offer}</b> "
                f"({state.current_offer_index + 1}/{len(state.offers)})."
            ),
        )
        return

    # 4) –Ø–∫—â–æ –¥–∞–Ω—ñ —î ‚Äî –∫–∞–Ω–æ–Ω—ñ–∫–∞–ª—ñ–∑—É—î–º–æ –∫—Ä–∞—ó–Ω–∏ —Ç–∞ –∞–≥—Ä–µ–≥—É—î–º–æ
    work["canon_en"] = work["–ö—Ä–∞—ó–Ω–∞"].apply(
        lambda x: to_canonical_en(x, state.country_map_uk_to_en, state.country_canon, state.country_map_ru_to_en)
    )

    dep_by_country = (
        work.groupby("canon_en")["–°—É–º–∞ –¥–µ–ø–æ–∑–∏—Ç—ñ–≤"]
        .agg(["sum", "count"]).reset_index()
        .rename(columns={"sum": "total", "count": "count"})
    )

    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∞–≥—Ä–µ–≥–∞—Ç–∏ –≤ –ø–∞–º'—è—Ç—å –¥–ª—è —Ü—å–æ–≥–æ –æ—Ñ–µ—Ä—É
    state.offer_deposits[current_offer] = {
        row["canon_en"]: {"total": float(row["total"]), "count": int(row["count"])}
        for _, row in dep_by_country.iterrows()
    }

    # 5) –ü—ñ–¥—Å—É–º–∫–æ–≤–∞ —ñ–Ω—Ñ–æ –¥–ª—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
    countries_found = list(dep_by_country["canon_en"].unique())
    total_deposits = float(dep_by_country["total"].sum())

    # 6) –ü–µ—Ä–µ—Ö—ñ–¥ –¥–æ –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ –æ—Ñ–µ—Ä—É / —Ñ—ñ–Ω–∞–ª
    state.current_offer_index += 1
    if state.current_offer_index >= len(state.offers):
        final_df = build_final_output(state)
        send_final_table(message, final_df)
        user_states[message.chat.id] = UserState()  # reset
        return

    kb = types.InlineKeyboardMarkup()
    kb.add(types.InlineKeyboardButton("–ü—Ä–æ–ø—É—Å—Ç–∏—Ç–∏ —Ü–µ–π –æ—Ñ–µ—Ä", callback_data="skip_offer"))

    next_offer = state.offers[state.current_offer_index]
    summary = f"""
‚úÖ –ü—Ä–∏–π–Ω—è—Ç–æ –¥–∞–Ω—ñ –¥–ª—è <b>{current_offer}</b>
üìä –ó–Ω–∞–π–¥–µ–Ω–æ {len(countries_found)} –∫—Ä–∞—ó–Ω, –∑–∞–≥–∞–ª—å–Ω–∞ —Å—É–º–∞ –¥–µ–ø–æ–∑–∏—Ç—ñ–≤: {total_deposits:,.2f}

–ö—Ä–∞—ó–Ω–∏: {', '.join(countries_found[:5])}{' ...' if len(countries_found) > 5 else ''}

–ù–∞–¥—ñ—à–ª–∏ –Ω–∞—Å—Ç—É–ø–Ω—É –¥–æ–¥–∞—Ç–∫–æ–≤—É —Ç–∞–±–ª–∏—Ü—é –¥–ª—è <b>{next_offer}</b> ({state.current_offer_index + 1}/{len(state.offers)})
    """.strip()

    bot.send_message(message.from_user.id, summary, reply_markup=kb)


# ===================== BUILD FINAL =====================

def geo_to_canonical(
        geo: str,
        uk_to_en: Dict[str, str],
        canonical: Dict[str, str],
        ru_to_en: Optional[Dict[str, str]] = None,
) -> str:
    return to_canonical_en(geo, uk_to_en, canonical, ru_to_en)


def build_final_output(state: UserState) -> pd.DataFrame:
    agg = state.main_agg_df.copy()
    # Canonical GEO for matching
    agg["–ì–ï–û_canon"] = agg["–ì–ï–û"].apply(
        lambda g: geo_to_canonical(g, state.country_map_uk_to_en, state.country_canon, state.country_map_ru_to_en))

    rows: List[Dict[str, object]] = []
    for _, row in agg.iterrows():
        offer_name = str(row["–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É"])
        # If you have a real Offer ID elsewhere ‚Äî put it here. Fallback to offer_name.
        offer_id = offer_name

        geo_display = str(row["–ì–ï–û"])
        geo_canon = str(row["–ì–ï–û_canon"])
        spend_total = float(row["–ó–∞–≥–∞–ª—å–Ω—ñ –≤–∏—Ç—Ä–∞—Ç–∏"])

        dep_sum = 0.0  # Total Dep Sum ($)
        dep_cnt = 0  # FTD qty
        offer_map = state.offer_deposits.get(offer_name, {})
        if geo_canon in offer_map:
            dep_sum = float(offer_map[geo_canon]["total"])
            dep_cnt = int(offer_map[geo_canon]["count"])
        else:
            import difflib
            candidates = list(offer_map.keys())
            close = difflib.get_close_matches(geo_canon, candidates, n=1, cutoff=0.6)
            if close:
                dep_sum = float(offer_map[close[0]]["total"])
                dep_cnt = int(offer_map[close[0]]["count"])

        rows.append({
            "Subid": "",  # empty
            "Offer ID": offer_id,  # from main table (fallback = name)
            "–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É": offer_name,  # Offer Name
            "–ì–ï–û": geo_display,  # Country
            "FTD qty": dep_cnt,  # count
            "Total Spend": spend_total,  # $
            "Total Dep Amount": dep_sum,  # $ (your naming; this is the sum)
            # rest computed later in Excel
        })

    # Order primary columns; computed ones will be added in send_final_table
    df = pd.DataFrame(rows, columns=[
        "Subid", "Offer ID", "–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É", "–ì–ï–û", "FTD qty", "Total Spend", "Total Dep Amount"
    ])
    return df


# ===================== SENDER =====================

def send_final_table(message: types.Message, df: pd.DataFrame):
    bio = io.BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        # Rebuild to requested order
        base_cols = [
            "Subid", "Offer ID", "–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É", "–ì–ï–û",
            "FTD qty", "Total Spend", "Total Dep Amount"
        ]
        df = df[base_cols].copy()

        st = user_states.get(message.chat.id)

        # ‚úÖ —Ñ–æ–ª–±–µ–∫ –Ω–∞ –≥–ª–æ–±–∞–ª—å–Ω—ñ –ø–∞—Ä–∏
        pairs = (getattr(st, "current_pairs", None) or GLOBAL_CURRENT_PAIRS)
        p35 = (getattr(st, "plus35_pairs", None) or GLOBAL_PLUS35_PAIRS)

        # (–Ω–µ –æ–±–æ–≤'—è–∑–∫–æ–≤–æ) –ª–æ–∫–∞–ª—å–Ω–∏–π –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ç–æ—Ä
        def _n(s: str) -> str:
            s = str(s or "").strip().lower()
            s = s.replace("‚Äô", "'").replace("`", "'").replace("‚Äì", "-").replace("‚Äî", "-")
            return " ".join(s.split())

        def _pair(row):
            return (_n(row.get("–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É", "")), _n(row.get("–ì–ï–û", "")))

        # –ö–æ–ª–æ–Ω–∫–∞ Current
        if pairs:
            df["Current"] = df.apply(lambda r: "+" if _pair(r) in pairs else "-", axis=1)
        else:
            df["Current"] = "-"

        # ---- NEW: round numeric inputs before write ----
        df["Total Spend"] = pd.to_numeric(df["Total Spend"], errors="coerce").round(2)
        df["Total Dep Amount"] = pd.to_numeric(df["Total Dep Amount"], errors="coerce").round(2)
        df["FTD qty"] = pd.to_numeric(df["FTD qty"], errors="coerce").fillna(0).astype(int)
        # -------------------------------------------------

        final_cols = [
            "Subid", "Offer ID", "–ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É", "–ì–ï–û",
            "FTD qty", "Total spend", "Total+%", "CPA", "CPA Target", "–°P/–ß",
            "Total Dep Amount", "My deposit amount", "C. profit Target 40%", "C. profit Target 50%",
            "CAP", "–û—Å—Ç–∞—Ç–æ–∫ CAP", "Current"
        ]

        df.rename(columns={"Total Spend": "Total spend"}, inplace=True)

        # Placeholders
        df["Total+%"] = None
        df["CPA"] = None
        df["CPA Target"] = None
        df["–°P/–ß"] = None
        df["My deposit amount"] = None
        df["C. profit Target 40%"] = None
        df["C. profit Target 50%"] = None
        df["CAP"] = ""
        df["–û—Å—Ç–∞—Ç–æ–∫ CAP"] = ""

        df = df[final_cols]

        df.to_excel(writer, index=False, sheet_name="Result")

        wb = writer.book
        ws = writer.sheets["Result"]

        from openpyxl.styles import PatternFill, Alignment, Font
        from openpyxl.formatting.rule import FormulaRule

        first_row = 2
        last_row = ws.max_row

        # === –§–æ—Ä–º—É–ª–∏ ===
        # G: Total+% ‚Äî –¢–ï–ü–ï–† –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º plus35_pairs
        for r in range(first_row, last_row + 1):
            offer_val = ws[f"C{r}"].value  # –ù–∞–∑–≤–∞ –û—Ñ—Ñ–µ—Ä—É
            geo_val = ws[f"D{r}"].value  # –ì–ï–û

            mul = 1.35 if (p35 and (_n(offer_val), _n(geo_val)) in p35) else 1.3
            ws[f"G{r}"].value = f"=F{r}*{mul}"  # Total+%

            ws[f"H{r}"].value = f"=IFERROR(G{r}/E{r},\"\")"  # CPA
            ws[f"I{r}"].value = cpa_target_for_geo(ws[f"D{r}"].value)  # CPA Target
            ws[f"J{r}"].value = f"=IFERROR(K{r}/E{r},\"\")"  # –°P/–ß
            ws[f"L{r}"].value = f"=IFERROR(K{r}/G{r}*100,0)"  # My deposit amount
            ws[f"M{r}"].value = f"=G{r}*0.4"  # Profit 40%
            ws[f"N{r}"].value = f"=G{r}*0.5"  # Profit 50%

        # ---- –§–æ—Ä–º–∞—Ç–∏ —á–∏—Å–µ–ª ----
        # Integers: E (FTD qty)
        for r in range(first_row, last_row + 1):
            ws[f"E{r}"].number_format = "0"

        # Two decimals: F..N (–æ–∫—Ä—ñ–º I ‚Äî —Ç–∞–º —Ü—ñ–ª–µ –∑–Ω–∞—á–µ–Ω–Ω—è —Ü—ñ–ª—ñ)
        two_dec_cols = ["F", "G", "H", "J", "K", "L", "M", "N"]
        for col in two_dec_cols:
            for r in range(first_row, last_row + 1):
                ws[f"{col}{r}"].number_format = "0.00"

        # --- Header styling ---
        for col in range(1, 17):  # A..P
            ws.cell(row=1, column=col).font = Font(bold=True)
            ws.cell(row=1, column=col).alignment = Alignment(horizontal="center")

        widths = {
            "A": 10, "B": 12, "C": 22, "D": 16, "E": 10, "F": 14, "G": 12, "H": 10, "I": 12,
            "J": 10, "K": 16, "L": 18, "M": 18, "N": 18, "O": 12, "P": 16
        }
        for col, w in widths.items():
            ws.column_dimensions[col].width = w

        # --- Conditional formatting ---
        data_range = f"A{first_row}:P{last_row}"
        grey = PatternFill("solid", fgColor="BFBFBF")
        green = PatternFill("solid", fgColor="C6EFCE")
        yellow = PatternFill("solid", fgColor="FFEB9C")
        red = PatternFill("solid", fgColor="FFC7CE")

        # Grey: E = 0
        ws.conditional_formatting.add(
            data_range, FormulaRule(formula=["$E2=0"], fill=grey, stopIfTrue=True)
        )
        # Green: INT(H) <= INT(I) AND L > 39
        ws.conditional_formatting.add(
            data_range, FormulaRule(formula=["AND($E2>0,INT($H2)<=INT($I2),$L2>39)"], fill=green, stopIfTrue=True)
        )
        # Yellow: (INT(H) <= INT(I)) OR (L > 39 AND H < I*1.31)
        ws.conditional_formatting.add(
            data_range, FormulaRule(formula=["AND($E2>0,OR(INT($H2)<=INT($I2),AND($L2>39,$H2<$I2*1.31)))"], fill=yellow,
                                    stopIfTrue=True)
        )
        # Red:
        ws.conditional_formatting.add(
            data_range, FormulaRule(
                formula=["OR(AND($E2>0,$H2>$I2*1.3,$L2>39),AND($E2>0,INT($H2)>INT($I2),$L2<39))"],
                fill=red, stopIfTrue=True
            )
        )

    bio.seek(0)
    bot.send_document(
        message.chat.id,
        bio,
        visible_file_name="result.xlsx",
        caption="–§—ñ–Ω–∞–ª—å–Ω–∞ —Ç–∞–±–ª–∏—Ü—è –∑ –≥–æ—Ç–æ–≤–∏–º –∞–Ω–∞–ª—ñ–∑–æ–º üìä"
    )


# ===================== MAIN =====================
if __name__ == "__main__":
    print("Bot is running...")
    bot.infinity_polling(skip_pending=True)
